---
aliases: 
tags: 
type: literature
---

# Anil Seth - Being You: A New Science of Consciousness

_previous note:_ [[losing one's self]]

> The Brain—is wider than the Sky— For—put them side by side— The one the other will contain With ease—and You—beside—
-- Emily Dickinson (Location 32)


> It’s an act of transformation, a kind of magic: anaesthesia is the art of turning people into objects. (Location 74)

> I have a childhood memory of looking in the bathroom mirror, and for the first time realising that my experience at that precise moment – the experience of being me – would at some point come to an end, and that ‘I’ would die. (Location 85)
- [[mirror with phone]]

> Whether you’re a scientist or not, consciousness is a mystery that matters. For each of us, our conscious experience is all there is. Without it there is nothing at all: no world, no self, no interior and no exterior. (Location 100)

> Without consciousness, it may hardly matter whether you live for another five years or 4another five hundred. In all that time there would be nothing it would be like to be you. (Location 108)

> At each stage in this process you exist, but the notion that there is a single unique conscious self (a soul?) that persists over time may be grossly mistaken. Indeed, one of the most compelling aspects of the mystery of consciousness is the nature of self. Is consciousness possible without self-consciousness, and if so would it still matter so much? (Location 116)

> For me, these questions evoke the uncanny sympathy I felt when watching Dave Bowman destroy 5HAL’s personality in the film 2001: A Space Odyssey, by the simple act of removing its memory banks, one by one. (Location 123)

> hope to show you is that by accounting for properties of consciousness, in terms of mechanisms in brains and bodies, the deep metaphysical whys and hows of consciousness become, little by little, less mysterious. (Location 141)

> I use the word ‘wetware’ to underline that brains are not computers made of meat. They are chemical machines as much as they are electrical networks. Every brain that has ever existed has been part of a living body, embedded in and interacting with its environment – an environment which in many cases contains other embodied brains. Explaining the properties of consciousness in terms of biophysical mechanisms requires understanding brains – and conscious minds – as embodied and embedded systems. (Location 143)

> In my view, consciousness has more to do with being alive than with being intelligent. We are conscious selves precisely because we are beast machines. I will make the case that experiences of being you, or of being me, emerge from the way the brain predicts and controls the internal state of the body. The essence of selfhood is neither a rational mind nor an immaterial soul. It is a deeply embodied biological process, a process that underpins the simple feeling of being alive that is the basis for all 7our experiences of self, indeed for any conscious experience at all. Being you is literally about your body. (Location 150)

> By the end of the book, you’ll understand that our conscious experiences of the world and the self are forms of brain-based prediction – ‘controlled hallucinations’ – that arise with, through, and because of our living bodies. (Location 160)

> Our conscious experiences are part of nature just as our bodies are, just as our world is. And when life ends, consciousness will end too. (Location 173)

> The novelist Julian Barnes, in his meditation on mortality, puts it perfectly. When the end of consciousness comes there is nothing – really nothing – to be frightened of. (Location 175)

> This way of putting things is most closely associated with the philosopher Thomas Nagel, who in 1974 published a now legendary article called ‘What is it like to be a bat?’ in which he argued that while we humans could never experience the experiences of a bat, there nonetheless would be something it is like for the bat, to be a bat.* I’ve always favoured Nagel’s approach because it emphasises phenomenology: the subjective properties of conscious experience, such as why a visual experience has the form, structure, and qualities that it does, as compared to the subjective properties of an emotional experience, or of an olfactory experience. These properties are sometimes also called qualia in philosophy: 12the redness of red, the pang of jealousy, the sharp pain or dull throb of a toothache. (Location 191)

> Wherever there is experience, there is phenomenology; and wherever there is phenomenology, there is consciousness. (Location 199)

> The definition of consciousness as ‘any kind of subjective experience whatsoever’ is admittedly simple and may even sound trivial, but this is a good thing. When a complex phenomenon is incompletely understood, prematurely precise definitions can be constraining and even misleading. (Location 228)

> (A ‘mechanism’ – to be clear – can be defined as a system of causally interacting parts that produce effects.) (Location 252)

- [[somatics unlimited]]


> ‘[E]ven when we 16have explained the performance of all the functions in the vicinity of experience – perceptual discrimination, categorization, internal access, verbal report – there may still remain a further unanswered question: Why is the performance of these functions accompanied by experience?’ (Location 254)

- Chalmers quote

> My preferred philosophical position, and the default assumption of many neuroscientists, is physicalism. This is the idea that the universe is made of physical stuff, and that conscious states are either identical to, or somehow emerge from, particular arrangements of this physical stuff. Some philosophers use the term materialism instead of physicalism, but for our purposes they can be treated synonymously. (Location 261)

> Nowadays few philosophers or scientists would explicitly sign up for this view. But for many people, at least in the West, dualism remains beguiling. The seductive intuition that 17conscious experiences seem non-physical encourages a ‘naïve dualism’ where this ‘seeming’ drives beliefs about how things actually are. (Location 268)

> Taking functionalism at face value, as many do, carries the striking implication that consciousness is something that can be 18simulated on a computer. Remember that for functionalists, consciousness depends only on what a system does, not on what it is made of. This means that if you get the functional relations right – if you ensure that a system has the right kind of ‘input–output mappings’ – then this will be enough to give rise to consciousness. In other words, for functionalists, simulation means instantiation – it means coming into being, in reality. (Location 284)

> the main problems with panpsychism don’t lie with its apparent craziness – after all, some crazy ideas turn out to be true, or at least useful. The main problems are that it doesn’t really explain anything and that it doesn’t lead to testable hypotheses. It’s an 19easy get-out to the apparent mystery posed by the hard problem, and taking it on ushers the science of consciousness down an empirical dead end. (Location 298)

> Here’s why the zombie idea is supposed to provide an argument against physicalist explanations of consciousness. If you can imagine a zombie, this means you can conceive of a world that is indistinguishable from our world, but in which no consciousness is happening. And if you can conceive of such a world, then consciousness cannot be a physical phenomenon. (Location 330)

> According to the real problem, the primary goals of consciousness science are to explain, predict, and control the phenomenological properties of conscious experience. This means explaining why a particular conscious experience is the way it is – why it has the phenomenological properties that it has – in terms of physical mechanisms and processes in the brain and body. These explanations should enable us to predict when specific subjective 23experiences will occur, and enable their control through intervening in the underlying mechanisms. In short, addressing the real problem requires explaining why a particular pattern of brain activity – or other physical process – maps to a particular kind of conscious experience, not merely establishing that it does. (Location 351)

- this last part is intriguing re [[authentic movement]]

> Explanation, prediction, and control. These are the criteria by which most other scientific projects are assessed, regardless of how mystifying their target phenomena might initially appear. (Location 380)

- C-DaRE invites

> Of course, the parallel between life and consciousness is not perfect. Most conspicuously, the properties of life are objectively describable, whereas the explanatory targets of consciousness science are subjective – they exist only in the first person. However, this is not an insurmountable barrier; it mostly means the relevant data, because they are subjective, are harder to collect. (Location 459)


> Applying the same strategy to consciousness, in this book I will focus on level, content, and self as the core properties of what being you is all about. (Location 465)


> Conscious level concerns ‘how conscious we are’ – on a scale from complete absence of any conscious experience at all, as in coma or brain death, all the way to vivid states of awareness that accompany normal waking life. Conscious content is about what we are conscious of – the sights, sounds, smells, emotions, moods, thoughts, and beliefs that make up our inner universe. Conscious contents are all varieties of perception – brain-based interpretations of sensory signals that collectively make up our conscious experiences. (Perception, as we will see, can be both conscious and unconscious.) Then there’s conscious self – the specific experience of being you, 31and the guiding theme of this book. The experience of ‘being a self’ is a subset of conscious contents, encompassing experiences of having a particular body, a first-person perspective, a set of unique memories, as well as experiences of moods, emotions, and ‘free will’. Selfhood is probably the aspect of consciousness that we cling to most tightly, so tightly that it can be tempting to confuse self-consciousness (the experience of being a self) with consciousness itself (the presence of any kind of subjective experience, of any phenomenology, whatsoever). (Location 467)


> There are as many different ways of being conscious as there are different conscious organisms. (Location 483)


> fully satisfying science: Another way of putting this ambition comes from the philosophers Susan Hurley and Alva Noë, who distinguish between ‘comparative’ explanatory gaps, which have to do with explaining why different experiences have the specific phenomenological properties that they do, and the ‘absolute’ explanatory gap, which is the (hard) problem of why and how there is such a thing as phenomenology at all. We can think of the real problem as exhaustively addressing comparative explanatory gaps in order to resolve, and perhaps dissolve, the absolute explanatory gap. See Hurley & Noë (2003). (Location 558)


> This paper is one of the most influential in all philosophy of mind. According to Nagel, ‘an organism has conscious mental states if and only if there is something that it is like to be that organism – something it is like for the organism’. Nagel (1974), p. 2 (italics in original). (Location 573)


> But even if the story of consciousness turns out differently, to be less like temperature and more like life, as I suspect it will, the 36ability to make precise measurements nevertheless remains an essential step in building explanatory bridges; in explaining, predicting, and controlling the nature of subjective experiences. In either scenario, measurement turns the qualitative into the quantitative, the vague into the precise. (Location 631)


> Conscious level is not the same thing as physiological arousal. While the two are often highly correlated, consciousness (awareness) and wakefulness (arousal) can come apart in various ways, which is enough to show that they cannot depend on the same underlying biology. (Location 651)


> To test how different parts of the cortex were talking to each other, they stimulated activity in one location and recorded how this pulse of activity spread to other cortical regions over space and time. They did this by combining two techniques: EEG and transcranial magnetic stimulation (TMS). A TMS rig is a precisely controlled electromagnet which allows a researcher to inject a short and sharp pulse of energy directly into the brain through the skull, while EEG in this case is used to record the brain’s response to this zapping. It’s like banging on the brain with an electrical hammer and listening to the echo. (Location 675)


> While the difference between the two conditions is often easy to see simply by eyeballing the data, what’s truly exciting about this work is that the complexity of the echo can be quantified. It is possible to put a number to it to specify the magnitude of complexity. The approach is called ‘zap and zip’: use TMS to zap the cortex, and use a computer algorithm to ‘zip’ the response, the electrical echo, into a single number. (Location 690)


> The ‘zip’ algorithm – which 41calculates what’s called ‘Lempel-Ziv-Welch complexity’, or ‘LZW complexity’ for short – is a popular way of estimating the algorithmic complexity for any given sequence. (Location 699)


> Subsequent studies have gone further still, using Owen’s method not only for diagnosis but also for communication. In a 2010 study led by Martin Monti, a patient who had been admitted with a diagnosis of vegetative state was able to answer yes/no questions by imagining playing tennis for ‘yes’ and imagining walking around their house for ‘no’. A laborious way of communicating, for sure, but a life-changing development for those with no other way to make themselves understood. (Location 764)


> This way of thinking is symptomatic of the human exceptionalism that has repeatedly plagued biology, as it has darkened the history of human thought everywhere. (Location 779)

- C-DaRE invites: Are our bodies special? Science and the body


> An important consequence of taking multidimensional levels of consciousness seriously is that sharp distinctions between conscious level and conscious content disappear. It becomes meaningless to completely separate how conscious you are from what you are conscious of. A ‘one size fits all’ measure of consciousness – of 48the sort we might expect if we take the temperature analogy too literally – may never be enough. (Location 797)


> In the psychedelic state, vivid perceptual hallucinations are frequently accompanied by unusual experiences of selfhood often described as ‘ego dissolution’, where the boundaries between self and world, and other people, appear to shift or dissolve. These departures from ‘normal’ conscious experience are so pervasive that the psychedelic state might represent not only a change 49in conscious contents, but also a change in overall conscious level. (Location 811)


> Tononi and Edelman asked what was characteristic about conscious experiences in general. They made a simple but profound observation: that conscious experiences – all conscious experiences – are both informative and integrated. From this starting point, they made claims about the neural basis of every conscious experience, not just of specific experiences of seeing red, or feeling jealous, or suffering a toothache. (Location 865)


> Conscious experiences are 53informative because every conscious experience is different from every other conscious experience that you have ever had, ever will have, or ever could have. (Location 871)


> At any one time we have precisely one conscious experience out of vastly many possible conscious experiences. Every conscious experience therefore delivers a massive reduction of uncertainty, since this experience is being had, and not that experience, or that experience, and so on. And reduction of uncertainty is – mathematically – what is meant by information. (Location 876)


> On this view, the ‘what-it-is-like-ness’ of any specific conscious experience is defined not so much by what it is, but by all the unrealised but possible things that it is not. An experience of pure redness is the way that it is, not because of any intrinsic property of ‘redness’, but because red is not blue, green, or any other colour, or any smell, or a thought or a feeling of regret or indeed any other form of mental content whatsoever. Redness is redness because of all the things it isn’t, and the same goes for all other conscious experiences. (Location 882)


> Conscious experiences are not only highly informative, they are also integrated. Exactly what is meant by consciousness being ‘integrated’ is still much debated, but essentially it means that every conscious experience appears as a unified scene. We do not experience colours separately from their shapes, nor objects independently of their background. (Location 887)


> The key move made by Tononi and Edelman was to propose that if every conscious experience is both informative and unified at the level of phenomenology, then the neural mechanisms underlying conscious experiences should also exhibit both of these properties. That it is in virtue of expressing both of these properties that neural mechanisms do not merely correlate with, but actually account for, core phenomenological features of every conscious experience. (Location 892)


> In the middle lie systems in which individual elements may do different things, but in which there is some degree of co-ordination so that the system behaves to some extent ‘as a whole’. This is the domain where both integration and information are to be found. It is also the middle ground between order and disorder, and it is here that systems are typically called ‘complex’. (Location 905)


> At the core of IIT is a single measure called ‘Φ’ (the Greek letter phi, pronounced fy). The easiest way to think about Φ is that it measures how much a system is ‘more than the sum’ of its parts, in terms of information. (Location 1054)


> In IIT, Φ measures the amount of information a system generates ‘as a whole’, over and above the amount of information generated by its parts independently. This underpins the main claim of the theory, which is that a system is conscious to the extent that its whole generates more information than its parts. (Location 1057)


> According to IIT, the level of Φ is intrinsic to a system (meaning that it does not depend on an external observer), and it is identical to the amount of consciousness associated with that system. High Φ, lots of consciousness. Zero Φ, no consciousness. This is why IIT is the ultimate expression of a temperature-based view of consciousness. (Location 1061)


> Information in IIT must therefore be treated as intrinsic to a system, not as relative to an external observer. It must be defined in a way that does not depend on any external observer. It must be information ‘for’ the system itself – not for anyone or anything else. If not, the identity relation between Φ and consciousness at the core of IIT cannot hold. (Location 1121)


> In this situation, the empirical distribution would not contain a twelve, but the maximum entropy distribution would, because a twelve could have happened, even though in this particular sequence of throws it didn’t. (Location 1132)


> Unfortunately, often all we have access to are the dynamics of a system, to what a system does, rather than to what it could do. This 67is certainly true for brains. I can record what your brain does, at varying levels of detail, but I have no way of knowing its complete physical structure, nor can I perturb its activity in all possible ways. For these reasons, the most distinctive claim of IIT – that Φ actually is consciousness – is also the least testable. (Location 1141)


> IIT’s panpsychism is a restrained panpsychism, not the sort in which consciousness is spread out 70through the entire universe like a thin layer of jam. Rather, consciousness is to be found wherever integrated information – Φ – is to be found. This could be here and there, but not everywhere. (Location 1186)


> From our perspective, this means treating ‘integration’ and ‘information’ as general properties of conscious experiences to be explained, not as axiomatic claims about what consciousness actually ‘is’. In other words, treating consciousness as being more like life than like temperature. (Location 1204)


> When trying to form perceptions, all the brain has to go on is a constant barrage of electrical signals which are only indirectly related to things out there in the world, whatever 76they may be. (Location 1283)


> A coffee cup out there in the world leads to a perception of a coffee cup generated within the brain. As to who or what is doing the perceiving – well, that’s the ‘self’, isn’t it, the ‘I behind the eyes’ one might say, the recipient of wave upon 77wave of sensory data, which uses its perceptual readouts to guide behaviour, to decide what to do next. There’s a cup of coffee over there. I perceive it and I pick it up. I sense, I think, and then I act. (Location 1297)

- [[losing one's self]]: the language of I is a massive limitation. Avoid it?


> But Wittgenstein was driving at something deeper. His real message for Anscombe was that even with a greater understanding of how things actually are, at some level things still appear the same way they always did. The sun rises in the east and sets in the west, same as always. (Location 1338)


> Perceptions do not come from the bottom up or the outside in, they come primarily from the top down, or the inside out. What we experience is built from the brain’s predictions, or ‘best guesses’, about the causes of sensory signals. (Location 1346)


> This is by no means a wholly new idea. The first glimmers of a top-down theory of perception emerge in ancient Greece, with Plato’s Allegory of the Cave. Prisoners, chained and facing a blank wall all their lives, see only the play of shadows cast by objects passing by a fire behind them, and they give the shadows names, because for them the shadows are what is real. The allegory is that our own conscious perceptions are just like these shadows, indirect reflections of hidden causes that we can never directly encounter. (Location 1349)


> Hundreds of years later again, Immanuel Kant realised that the chaos of unrestricted sensory data would always remain meaningless 81without being given structure by pre-existing conceptions, which for him included a priori frameworks like space and time. Kant’s term noumenon refers to ‘things in themselves’ – Ding an sich – a mind-independent reality that will always be inaccessible to human perception, hidden behind a sensory veil. (Location 1355)


> In neuroscience the story gets going with the German physicist and physiologist Hermann von Helmholtz. In the late nineteenth century, among a string of influential contributions, Helmholtz proposed the idea of perception as a process of ‘unconscious inference’. The contents of perception, he argued, are not given by sensory signals themselves but have to be inferred by combining these signals with the brain’s expectations or beliefs about their causes. In calling this process unconscious, Helmholtz understood that we are not aware of the mechanisms by which perceptual inferences happen, only of the results. Perceptual judgements – his ‘unconscious inferences’ – keep track of their causes in the world by continually and actively updating perceptual best guesses as new sensory data arrive. Helmholtz saw himself as providing a scientific version of Kant’s insight that perception cannot allow us to know things in the world directly – that we can only infer that things are there, behind the sensory veil. (Location 1359)


> My own take on Helmholtz’s enduring idea, and on its contemporary incarnations, is best captured by the notion of perception as controlled hallucination, a phrase I first heard from the British psychologist Chris Frith many years ago.† The essential ingredients of the controlled hallucination view, as I think of it, are as follows. (Location 1378)


> By adjusting top-down predictions so as to suppress bottom-up prediction errors, the brain’s perceptual best guesses maintain their grip on their causes in the world. In this view, perception happens through a continual process of prediction error minimisation. (Location 1388)


> The third and most important ingredient in the controlled hallucination view is the claim that perceptual experience – in this case the subjective experience of ‘seeing a coffee cup’ – is determined by the content of the (top-down) predictions, and not by the (bottom-up) sensory signals. We never experience sensory signals themselves, we only ever experience interpretations of them. (Location 1391)


> This means that colour is not a definite property of things-in-themselves. Rather, colour is a useful device that evolution has hit upon so that the brain can recognise and keep track of objects in changing lighting conditions. (Location 1426)


> When I have the subjective 86experience of seeing the red chair in the corner of the room, this doesn’t mean that the chair actually is red – because what could it even mean for a chair to possess a phenomenological property like redness? Chairs aren’t red just as they aren’t ugly or old-fashioned or avant-garde. Instead, the surface of the chair has a particular property, the way-in-which-it-reflects-light, that my brain keeps track of through its mechanisms of perception. Redness is the subjective, phenomenological aspect of this process. (Location 1427)


> There is no redness-as-such in the world or in the brain. As Paul Cézanne said, ‘colour is the place where our brain and the universe meet.’ (Location 1442)


> The larger claim here is that this applies far beyond the realm of colour experience. It applies to all of perception. The immersive multisensory panorama of your perceptual scene, right here and right now, is a reaching out from the brain to the world, a writing as much as a reading. The entirety of perceptual experience is a neuronal fantasy that remains yoked to the world through a continuous making and remaking of perceptual best guesses, of controlled hallucinations. (Location 1444)


> The fact that people have such different experiences and report them with such confidence, for the very same image, is compelling 89evidence that our perceptual experiences of the world are internal constructions, shaped by the idiosyncrasies of our personal biology and history. (Location 1470)


> The function of perception, at least to a first approximation, is to figure out the most likely causes of the sensory signals, not to deliver awareness of the sensory signals themselves – whatever that might mean. (Location 1494)


> One important implication of this principle is that we never experience the world ‘as it is’. Indeed, as Kant pointed out with his noumenon, it is difficult to know what it would mean to do so. (Location 1517)


> So while we 93might be surprised when perceptual illusions – like those we’ve just encountered – reveal a discrepancy between what we see (or hear, or touch) and what’s there, we should be careful not to judge perceptual experiences solely in terms of their ‘accuracy’ in directly coinciding with reality. Accurate – ‘veridical’ – perception, understood this way, is a chimera. The controlled hallucination of our perceptual world has been designed by evolution to enhance our survival prospects, not to be a transparent window onto an external reality, a window that anyway makes no conceptual sense. (Location 1519)


> Enlightenment philosopher John Locke called ‘primary’ and ‘secondary’ qualities. Locke proposed that the primary qualities of an object are those that exist independently of an observer, such as occupying space, having solidity, and moving. An oncoming train has these primary qualities in abundance, which is why jumping in front of one is a bad idea, whether or not you are observing it, and whatever beliefs you might hold about the nature of perception. Secondary qualities are those whose existence does depend on an 94observer. These are properties of objects that produce sensations – or ‘ideas’ – in the mind, and cannot be said to independently exist in the object. Colour is a good example of a secondary quality, since the experience of colour depends on the interaction of a particular kind of perceptual apparatus with an object. (Location 1530)


> The familiar but completely wrong idea that humans have only five senses can be traced back to Aristotle’s De Anima – ‘On the Soul’ – written around 350 BC. (Location 1599)


> But it is Bayes whose name is forever tied to a way of reasoning called ‘inference to the best explanation’, the insights from which are central to understanding how conscious perceptions are built from brain-based best guesses. (Location 1615)


> Induction involves reaching conclusions through extrapolating from a series of observations: the sun has risen in the east for all of recorded history, therefore it always rises in the east. 98Unlike deductive inferences, inductive inferences can be wrong: the first three balls I pulled out of the bag were green, therefore all balls in the bag are green. This may or may not be true. (Location 1622)


> Abductive reasoning – the sort formalised by Bayesian inference – is all about finding the best explanation for a set of observations, when these observations are incomplete, uncertain, or otherwise ambiguous. (Location 1625)


> In seeking the ‘best explanation’, abductive reasoning can be thought of as reasoning backward, from observed effects to their most likely causes, rather than forward, from causes to their effects – as is the case for deduction and induction. (Location 1627)


> Did it rain overnight? Perhaps, but it could also be that you forgot to turn off your garden sprinkler. The aim is to find the best explanation, or hypothesis, for what you see: given the lawn is wet, what is the probability (i) that it rained overnight, or (ii) that you left the sprinkler on? In other words, we want to infer the most likely cause for the observed data. (Location 1630)


> Bayes’ rule is a mathematical recipe for going from what we already know (the prior) to what we should believe next (the posterior), based on what we are learning now (the likelihood). Priors, likelihoods, and posteriors are often called Bayesian ‘beliefs’ because they represent states of knowledge rather than states of the world. (Location 1633)


> Bayes’ rule combines priors and likelihoods to come up with posterior probabilities for each hypothesis. The rule itself is simple: the posterior is just the prior multiplied by the likelihood, and divided by a second prior (this is the ‘prior on the data’ – which in this case is the prior probability of a wet lawn – we don’t need to worry about this here since it is the same for each hypothesis). (Location 1644)


> In the philosophy of science, the Bayesian perspective has most in common with the views of the Hungarian philosopher Imre Lakatos, whose analysis focuses on what makes scientific research programmes work in practice, rather than on what they might ideally consist of. (Location 1674)


> For example, I’m aware that I have a strong prior belief that brains are Bayesian-like prediction machines. This strong belief will not only shape how I interpret experimental evidence, it will also determine the sorts of experiments that I do, to generate new evidence relevant to my beliefs. Sometimes I wonder how much evidence it would take to overturn my Bayesian belief that the brain is essentially Bayesian. (Location 1677)


> What Bayes’ theorem doesn’t do is specify how, in terms of neural mechanisms, the brain accomplishes these feats of best guessing. Answering this question returns us to the controlled hallucination theory of perception, and to the central claim that conscious contents are not merely shaped by perceptual predictions – they are these predictions. (Location 1735)


> The controlled hallucination view shares many features with other ‘predictive’ theories of perception and brain function, most prominently predictive processing. There is, however, an important difference of emphasis. Predictive processing is a theory about the 107mechanisms by which brains accomplish perception (and cognition, and action). The controlled hallucination view, by contrast, is about how brain mechanisms explain phenomenological properties of conscious perception. In other words, predictive processing is a theory about how brains work, whereas the controlled hallucination view takes this theory and develops it to account for the nature of conscious experiences. Importantly, both rest on the bedrock process of prediction error minimisation. (Location 1745)


> What this means, in practice, is that the brain continually adjusts the influence of sensory signals 109on perceptual inference. It does this by transiently altering their estimated precision. This is what is meant by the term ‘precision weighting’. Down-weighting estimated precision means that sensory signals have less influence on updating best guesses, while up-weighting means the opposite: a stronger influence of sensory signals on perceptual inference. In this way, precision weighting plays an essential role in choreographing the delicate dance between predictions and prediction errors needed to reach a perceptual best guess. (Location 1777)


> Although this sounds complicated, we are all intimately familiar with the role of precision weighting in perception. Increasing the estimated precision of sensory signals is nothing other than ‘paying attention’. When you pay attention to something – for example, really trying to see whether a gorilla is out there in the distance – your brain is increasing the precision weighting on the corresponding sensory signals, which is equivalent to increasing their estimated reliability, or turning up their ‘gain’. Thinking about attention this way can explain why sometimes we don’t see things, even if they are in plain view, and even if we are looking right at them. (Location 1782)


> Perception and action are so tightly coupled that they determine and define each other. Every action alters perception by changing the incoming sensory data, and every perception is the way it is in order to help guide action. There is simply no point to perception in the absence of action. We perceive the world around us in order to act effectively within it, to achieve our goals and – in the long run – to promote our prospects of survival. We don’t perceive the world as it is, we perceive it as it is useful for us to do so. (Location 1817)


> It may even be that action comes first. Instead of picturing the brain as reaching perceptual best guesses in order to then guide behaviour, we can think of brains as fundamentally in the business of generating actions, and continually calibrating these 112actions using sensory signals, so as to best achieve the organism’s goals. This view casts the brain as an intrinsically dynamic, active system, continually probing its environment and examining the consequences. (Location 1821)


> Any kind of bodily action will change sensory data in some way, whether it’s moving your eyes, walking into a different room, or tightening your stomach muscles. Even high-level ‘actions’, like 113applying for a new job or deciding to get married, will cascade down into sets of bodily actions which alter sensory inputs. (Location 1834)


> In the long run, actions are fundamental to learning – which here means improving the brain’s generative models by revealing more 114about the causes of sensory signals, and about the causal structure of the world in general. (Location 1849)


> We probably don’t think much about proprioception because, in some sense, it’s always there, but the simple fact that you can touch your nose with your eyes shut – try it! – demonstrates the essential role it plays in all our actions. From the perspective of active inference, touching my nose means allowing a suite of proprioceptive predictions about hand movement and position to become self-fulfilling – to overwhelm the sensory evidence that my fingers are currently not touching my nose. Precision weighting again plays an important role here. In order for proprioceptive predictions to make themselves come true, the prediction errors that are telling the brain where the body actually is must be attenuated, or down-weighted. This can be thought of as the opposite of 115paying attention – a kind of ‘disattention’ to the body, which allows it to move. (Location 1860)

- above re [[losing one's self]]

> Thinking about action in this way underlines how action and perception are two sides of the same coin. Rather than perception being the input and action being the output with respect to some central ‘mind’, action and perception are both forms of brain-based prediction. Both depend on a common process of Bayesian best guessing, on a carefully choreographed dance between perceptual predictions and sensory prediction errors, just with differences in who leads and who follows. (Location 1867)


> disattention: This idea can be experimentally tested, and it indeed turns out that during action, proprioceptive sensory sensitivity is reduced, just as would be expected (C. E. Palmer et al., 2016). The sensory attenuation accompanying action also provides a neat explanation for why we can’t tickle ourselves (H. Brown et al., 2013). (Location 1946)


> In the fluid intellectual atmosphere of Vienna at that time, the two cultures of art and science mingled to an unusual degree. Science wasn’t placed above art, in the all too familiar sense in which art, and the human responses it evokes, are considered to be things in need of scientific explanation. Nor did art place itself beyond the reach of science. Artists and scientists – and their critics – were allies in their attempts to understand human experience in all its richness and variety. No wonder the neuroscientist Eric Kandel called this period ‘the age of insight’, in his book of the same name. (Location 1964)


> One of the most influential ideas emerging from the age of insight is the ‘beholder’s share’, first introduced by Riegl and later popularised by one of the major figures in twentieth-century art history, Ernst Gombrich – himself born in Vienna in 1909. Their idea highlighted the role played by the observer – the beholder – in imaginatively ‘completing’ a work of art. The beholder’s share is that part of perceptual experience that is contributed by the perceiver 118and which is not to be found in the artwork – or the world – itself. (Location 1968)

> When we experience the world as being ‘really out there’, this is not a passive revealing of an objective reality, but a vivid and present projection – a reaching out to the world from the brain. (Location 1992)


> For anyone who doubts that the brain is the organ of experience, the hallucinations produced through LSD deliver a powerful corrective. (Location 2036)


> The general phenomenon of seeing patterns in things is called pareidolia (from the Greek ‘alongside’ and ‘image’). For humans – and some other animals – the significance of faces means that our brains come preloaded with strong face-related prior expectations. (Location 2041)


> All our experiences, whether we label them hallucinatory or not, are always and everywhere grounded in a projection of perceptual expectations onto and into our sensory environment. What we call ‘hallucination’ is what happens when perceptual priors are unusually strong, overwhelming the sensory data so that the brain’s grip on their causes in the world starts to slide. (Location 2050)


> The hallucination machine is an exercise in what we might call ‘computational phenomenology’: the use of computational models to build explanatory bridges from mechanisms to properties of perceptual experience. Its immediate value lies in matching the computational architecture of predictive perception to the phenomenology of hallucination. (Location 2088)


> In cognitive science, the phenomenology of objecthood has been most thoroughly explored by ‘sensorimotor contingency theory’. According to this theory, what we experience depends on a ‘practical mastery’ of how actions change sensory inputs. When we perceive something, the content of what we perceive is not carried by the sensory signals; instead it emerges from the 129brain’s implicit knowledge about how actions and sensations are coupled. On this view, vision – and all our perceptual modalities – are things an organism does, not passive information feeds for a centralised ‘mind’. (Location 2114)


> generative models can predict the sensory consequences of actions. These predictions are ‘conditional’ or ‘counterfactual’ in the sense that they are about what could happen or what could have happened to sensory signals, given some specific action. (Location 2127)


> The opposite situation, physical change without perceptual change, happens in ‘change blindness’. This can occur when some aspects of an environment change very slowly, or when everything is changing at once with only some features being relevant. In one powerful video example of this phenomenon,§ the entire lower half of an image can change colour – from red to purple – but because it happens slowly, over about forty seconds, most people don’t notice the change at all, even if they are looking directly at the changing part of the image. (Location 2162)


> Some people think that change blindness exposes a philosophical dilemma: after the image has changed colour, are you still experiencing red (even though it’s now purple), or are you now experiencing purple, in which case what were you experiencing before, given that you didn’t experience any change? The resolution is to deny the premise of the question and to recognise that perception of change is not the same as change of perception. The experience of change is another perceptual inference, another variety of controlled hallucination. (Location 2170)


> His idea is that we infer time based not on the ticking of an internal clock, but on the rate of change of perceptual contents in other modalities – and he devised a clever way to test it. (Location 2187)


> Warrick then showed the same videos to an artificial neural network that mimicked the operation of the human visual system. This network was in fact the same one we’d used in our hallucination machine. For each video, an estimate of duration was computed, based – roughly speaking – on the accumulated rate of change of activity within the network. These estimates did not involve any ‘inner clock’ whatsoever. Remarkably, the neural network estimates and the human estimates were virtually identical, showing the same biases by duration and by context. This shows that time perception can emerge, at least in principle, from a ‘best guess’ about the rate of change of sensory signals, without any need for an internal pacemaker. (Location 2194)


> With this set-up, we can now test ideas about the conditions in which people experience their environment as being real, and – perhaps more importantly – what it takes for this normally pervasive aspect of conscious experience to break down. These situations can and do happen, not only in cases like retinal afterimages, but also in debilitating psychiatric disorders such as depersonalisation and derealisation, where there can be a global loss of the experienced reality of the world, and of the self. (Location 2226)


> Why do we experience our perceptual constructions as being objectively real? On the controlled hallucination view, the purpose of perception is to guide action and behaviour – to promote the organism’s prospects of survival. We perceive the world not as it is, but as it is useful for us. It therefore makes sense that phenomenological properties – like redness, chairness, Cilla Black-ness, and causality-ness – seem to be objective, veridical, properties of an external existing environment. We can respond more quickly and more effectively to something happening in the world if we perceive that thing as really existing. (Location 2242)


> It is because our perceptions have the phenomenological character of ‘being real’ that it is extraordinarily difficult to appreciate that, in fact, perceptual experiences do not necessarily – or ever – directly correspond to things that have a mind-independent existence. A chair has a mind-independent existence; chairness does not. (Location 2258)


> Putting it the other way around, the hard problem of consciousness seems especially hard if we interpret the contents of our perceptual experience as really existing out there in the world. Which is exactly what the phenomenology of normal conscious perception encourages us automatically to do. (Location 2262)


> Delirium – a word surfacing from the depths of the sixteenth century – comes from the Latin delirare, to deviate, to be deranged. The dictionary calls it ‘an acutely disturbed state of mind characterised by restlessness, illusions, and incoherence’. (Location 2374)


> Up to a third of elderly patients entering acute care develop hospital-induced delirium, and the proportion is even higher for those having surgery. (Location 2395)


> The self is another perception, another controlled hallucination, though of a very special kind. From the sense of personal identity – like being a scientist, or a son – to experiences of having a body, and of simply ‘being’ a body, the many and varied elements of selfhood are Bayesian best guesses, designed by evolution to keep you alive. (Location 2422)


> We intuitively treat experiences of self differently from experiences of the world. When it comes to the experience of being you it seems harder to resist the intuition that it reveals a genuine property of the way things are – in this case an actual self – rather than a collection of perceptions. One intuitive consequence of assuming the existence of an actual self is that there can be only one such self, not two, or two thirds, or many. (Location 2451)


> Kant, in his Critique of Pure Reason, argued that the concept of the self as a ‘simple substance’ is wrong, and Hume talked about the self as a ‘bundle’ of perceptions. Much more recently, the German philosopher Thomas Metzinger wrote a very brilliant book called Being No One – a powerful deconstruction of the singular self. Buddhists have long argued that there is no such thing as a permanent self and through meditation have attempted to reach entirely selfless states of consciousness. (Location 2457)


> There are experiences of embodied selfhood that relate directly to the body. These include feelings of identification with the particular object that happens to be your body – we feel a certain sense of ownership over our body that doesn’t apply to other objects in the world. (Location 2481)


> running below these experiences we can find deeper, formless feelings of simply being an embodied living organism – of being a body – without any clearly definable spatial extent or specific content. (Location 2483)


> Just as experiences of redness are not indications of an externally existing ‘red’, experiences of unified selfhood do not signify the existence of an ‘actual self’. Indeed, the experience of being a unified self can come undone all too easily. The sense of personal identity, built on the narrative self, can erode or disappear entirely in dementia and in severe cases of amnesia, and it can be warped and distorted in cases of delirium, whether hospital-induced or not. (Location 2509)


> Out-of-body 154experiences and other dissociative disorders affect the perspectival self, while disorders of body ownership range from phantom limb syndrome – the experience of persistent, often painful sensations located in a limb that is no longer there – to somatoparaphrenia – the experience that one of your limbs belongs to someone else. In xenomelia – an extreme form of somatoparaphrenia – people experience an intense desire to amputate an arm or a leg, a drastic remedy which on rare occasions they actually carry out. (Location 2514)


> to somatoparaphrenia – the experience that one of your limbs belongs to someone else. In xenomelia – an extreme form (Location 2517)


> The experience of being me, or of being you, is a perception itself – or better, a collection of perceptions – a tightly woven bundle of neurally encoded predictions geared towards keeping your body alive. And this, I believe, is all we need to be, to be who we are. (Location 2520)


> The best-known example is the ‘rubber hand illusion’, first described more than twenty years ago, and now a cornerstone of research on embodiment. (Location 2524)


> The OBE-like experiences that sometimes accompany epileptic seizures can also be traced to disruptions in these processes. These experiences are usually divided into autoscopic hallucinations – in which you see your surroundings from a different perspective – and heautoscopic hallucinations (also known as doppelgänger hallucinations) – in which you see yourself from a different perspective. (Location 2572)

- above re [[losing one's self]], [[mirror with phone]] and [[perfect memory]]

> The aim of BeAnotherLab is to adapt body-swapping technology into novel ‘empathy generation’ devices. By experiencing what it’s like to perceive the world from within the virtual body of another, their idea is that empathy for the other’s situation will naturally follow. (Location 2591)


> Daanish had brought his team to Ojai to demonstrate their system, called The Machine to Be Another. Their set-up adds some clever choreography to the basic body-swapping principle that makes the effect even more powerful. Two participants put on headsets, and first look down at their laps, so that they see their partner’s body instead of their own. They then make a series of co-ordinated movements, following detailed instructions, and if they follow along closely enough their new body will appear to respond to their commands, strengthening the experience of being the other. After some time, mirrors are held up, and each sees the mirror image of the other, as if it were himself or herself. In the final act, the curtain separating the two people is removed, and they look at themselves from within the other’s body, before approaching each other and giving themselves a hug. (Location 2594)


> As I mentioned earlier, the typical experience in the rubber hand illusion is of somehow feeling the fake hand to be part of one’s body, while clearly knowing that it isn’t. (Location 2609)


> This kind of surprise, common in visual illusions, almost never happens in body ownership illusions. For me, the most compelling body illusion so far has been the body swapping I tried out in Ojai – but at no point was I ever close to believing I was now someone else, or somewhere else. (Location 2614)


> Unless studies of embodiment illusions take individual differences in suggestibility into account, which by and large they haven’t, it is difficult for them to say anything specific about the mechanisms involved. (Location 2626)


> There is a sharp contrast between these subjectively mild body ownership illusions and the powerfully altered experiences seen in clinical conditions like somatoparaphrenia, xenomelia, and phantom limb syndrome, or in the vivid out-of-body experiences associated with seizures or triggered by direct brain stimulation. These dramatic distortions are much more like classical visual illusions in that they elicit much greater conviction from those having the unusual experience. And for this reason they provide much stronger evidence that experiences of embodiment and perspective are indeed constructions of the brain. (Location 2629)


> These are the levels of selfhood at which it makes sense to associate the self with a name, with memories of the past and with plans for the future. At these levels we become aware that we have a self – we become truly self-aware. (Location 2638)


> These higher reaches of selfhood are fully dissociable from the embodied self. Many non-human animals, as well as human infants, may experience embodied selfhood without having – or missing – any accompanying sense of personal identity. (Location 2639)

- Note: Conflation of [[embodiment]] with selfhood! ([[losing one's self]])


> The kind of memory Clive has lost is his episodic, autobiographical memory – memory of events located in time and space (episodic), including, most importantly, those events involving himself (autobiographical). His diaries make for harrowing reading. They are filled with repeated descriptions of a ‘first’ awakening, one after the other, with previous assertions – some written just moments ago – crossed out and sometimes angrily obliterated. 8:31am       Now I am really, completely, awake 9:06am       Now I am perfectly, overwhelmingly awake 9:34am       Now I am superlatively, actually awake (Location 2651)


> These diaries, and the conversations with Clive recorded by his wife Deborah in her book Forever Today, testify to the assault on his sense of his personal identity inflicted by the damage to his brain (Location 2657)


> for more than thirty years, a continual starting from scratch, a fleeting presence with no stable ‘I’ around which to organise the flow of perceptions of world and self. (Location 2659)


> Memory is not the be-all and end-all of selfhood, but as this story tells us, and as many of us know through family and friends in the hinterlands of dementia or of Alzheimer’s disease, the persistence and continuity of self-perception is difficult to do without. (Location 2673)


> Here, I want to turn the lens inwards, to consider how the experience of being me depends, in a substantial way, on how I perceive others perceiving me. (Location 2685)

> One intriguing implication of this construal of the social self is that self-awareness – the higher reaches of selfhood comprising both narrative and social aspects – might necessarily require a social context. If you exist in a world without any other minds – more specifically, without any other relevant minds – there would be no need for your brain to predict the mental states of others, and therefore no need for it to infer that its own experiences and actions belong to any self at all. John Donne’s seventeenth-century meditation that ‘no man is an island’ could be literally true. (Location 2710)


> William James – the nineteenth-century pioneer of psychology – said it well: ‘Contrary to the perception of an object, which can be perceived from different perspectives or even cease to be perceived, we experience “the feeling of the same old body always there”.’ (Location 2726)


> We are becoming different people all the time. Our perceptions of self are continually changing – you are a slightly different person now than when you started reading this chapter – but this does not mean that we perceive these changes. This subjective blindness to the changing self has consequences. For one thing, it fosters the false intuition that the self is an immutable entity, rather than a bundle of perceptions. But this is not the reason that evolution designed our experiences of selfhood this way. I believe that the subjective stability of the self goes beyond even the change blindness warranted by our slowly changing bodies and brains. We live with an exaggerated, extreme 170form of self-change-blindness, and to understand why, we need to understand the reason we perceive ourselves in the first place. We do not perceive ourselves in order to know ourselves, we perceive ourselves in order to control ourselves. (Location 2734)


> We do not see things as they are, we see them as we are.           anaïs nin (Location 2814)


> Self-perception is not about discovering what’s out there in the world, or in here, in the body. It’s about physiological control and regulation – it’s about staying alive. (Location 2815)


> Then, in the seventeenth century, René Descartes did away with the many gradations of the Scala by cleaving the universe into just two modes of existence: res cogitans (mind stuff) and res extensa (matter stuff). (Location 2826)


> The historian Wallace Shugg summarised his views on the matter like this: The bodies of both man and beast … are merely machines that breathe, digest, perceive and move by means of the arrangement of parts. But only in man does reason direct bodily movements to meet all contingencies; only man gives evidence of his reason 173by using true speech. Without minds to direct their bodily movements or receive sensation, animals must be regarded as unthinking, unfeeling machines that move like clockwork. (Location 2836)


> Non-human animals are best thought of as bêtes-machines – in English, ‘beast machines’. (Location 2843)


> The French philosopher Julien Offray de La Mettrie, writing in the middle of the eighteenth century, certainly saw things this way. He extended Descartes’ beast machine argument to human beings, arguing that humans were machines too – l’homme machine (man machine) – and in doing so denying any special immaterial status for the soul while also questioning the existence of God. (Location 2848)


> La Mettrie was not one to finesse his arguments for the benefit of religious authority, and so his life rapidly became a lot more complicated than Descartes’. In 1748 he was forced to flee his adopted home in the Netherlands to work for the Prussian King Frederick in Berlin, where three years later he died after consuming an excess of pâté. (Location 2850)


> This brings us to the heart of my ‘beast machine’ theory of consciousness and self. Our conscious experiences of the world around us, and of ourselves within it, happen with, through, and because of our living bodies. Our animal constitution is not merely compatible with our conscious perceptions of self and world. My proposal is that we cannot understand the nature and origin of these conscious experiences, except in light of our nature as living creatures. (Location 2857)


> Underneath the layered expressions of selfhood involving memories of the past and plans for the future, before the explicit sense of personal identity, beneath the ‘I’ and even prior to the emergence of a first-person perspective and experiences of body ownership, there are deeper layers of selfhood still to be found. These bedrock layers are intimately tied to the interior of the body, rather than to the body as an object in the world, and they range from emotions and moods – what psychologists call ‘affective’ experiences – to a basal, formless, and ever-present sense of simply ‘being’ an embodied, living organism. (Location 2861)

- above re [[authentic movement]] and [[losing one's self]]


> The key property of interoceptive signals is that they reflect, in one way or another, how well physiological regulation of the body is going. In other words, how good a job the brain is doing of keeping its body alive. (Location 2878)


> Appraisal theories solve the problem of emotional range because each specific emotion now no longer needs a dedicated bodily state. Two closely related emotions – for example, listlessness and ennui – might be based on the same bodily state. The distinct emotions would emerge from different cognitive interpretations of this shared bodily condition. (Location 2895)


> Just like visual predictions, interoceptive predictions operate at many scales of time and space, supporting fluid, context-sensitive, multi-level best guesses about the causes of interoceptive signals. In this way, interoceptive inference solves the problem of emotional range without needing any bright-line distinction between the non-cognitive and the cognitive. Interoceptive inference is therefore more parsimonious than appraisal theory, because it involves just one process (Bayesian best guessing) rather than two (non-cognitive perception and cognitive evaluation), and because of this it also maps more comfortably onto the underlying brain anatomy. (Location 2931)


> The German neuroscientist Frederike Petzschner has recently shown that such responses, called ‘heartbeat evoked potentials’, are modulated by paying attention, as predicted by interoceptive inference. (Location 2939)


> This ‘cardio-visual synchrony’ method was also used by Jane Aspell and her colleagues in a ‘full body illusion’ setup, in which people viewed a virtual silhouette of their body. They too found that people reported stronger identification with the silhouette when it flashed in time with the heartbeat. While these studies are suggestive of interoceptive inference, more research is needed here too, in part because these experiments didn’t take account of individual differences in hypnotic suggestibility – a factor we’ve since learned is very important in body ownership experiments. They also depend on how aware a person is of their own heartbeat, a trait which has proven frustratingly difficult to measure. (Location 2944)


> Whether it’s fear, anxiety, joy, or regret – every emotional experience is rooted in top-down perceptual best guessing about the state of the body (and about the causes of this state). (Location 2951)


> According to William Powers’ ‘perceptual control theory’, we don’t perceive things in order to then behave in a particular way. Instead, as in the example of catching a cricket ball, we behave so that we end up perceiving things in a particular way. (Location 3037)


> Whether I’m sitting by my mother’s hospital bed, or fixing to escape from a bear, the form and quality of my emotional experiences are the way they are – desolate, hopeful, panicky, calm – because of the conditional predictions my brain is making about how different actions might impact my current and future physiological condition. (Location 3048)


> At the very deepest layers of the self, beneath even emotions and moods, there lies a cognitively subterranean, inchoate, difficult-to-describe experience of simply being a living organism. Here, experiences of selfhood emerge in the unstructured feeling of just ‘being’. This is where we reach the core of the beast machine theory: the proposal that conscious experiences of the world around us, and of ourselves within it, happen with, through, and because of our living bodies. (Location 3051)


> Just as with the outside world, the brain has no direct access to physiological states of the body, and so these states have to be inferred through Bayesian best guessing. As with all predictive perception, this best guessing is achieved through a brain-based process of prediction error minimisation. In the context of interoception, this is called interoceptive inference. Just as with vision and with hearing – just as with all perceptual modalities – interoceptive perception is a kind of controlled hallucination. (Location 3064)


> There is a useful term in physiology to describe this process: allostasis. Allostasis means the process of achieving stability through change, as compared to the more familiar term homeostasis, which simply means a tendency towards a state of equilibrium. We can think of interoceptive inference as being about the allostatic regulation of the physiological condition of the body. (Location 3078)


> Despite being firmly rooted in physiological regulation, emotions and moods are still mostly experienced at least in part as relating to things and situations beyond the self, outside the body. When I feel fear, I am usually afraid of some thing. But the very 190deepest levels of experienced selfhood – the inchoate feeling of ‘just being’ – seem to lack these external referents altogether. This, for me, is the true ground-state of conscious selfhood: a formless, shapeless, control-oriented perceptual prediction about the present and future physiological condition of the body itself. This is where being you begins, and it is here that we find the most profound connections between life and mind, between our beast machine nature and our conscious self. (Location 3083)


> Putting these ideas together, we perceive ourselves as stable over time in part because of a self-fulfilling prior expectation that our physiological condition is restricted to a particular range, and in part because of a self-fulfilling prior expectation that this condition does not change. In other words, effective physiological regulation may depend on systematically misperceiving the body’s internal state as being more stable than it really is, and as changing less than it really does. (Location 3108)


> Across 192every aspect of being a self, we perceive ourselves as stable over time because we perceive ourselves in order to control ourselves, not in order to know ourselves. (Location 3113)


> The most extreme examples of self-unreality happen in a rare delusion first described in 1880 by the French neurologist Jules Cotard. The embodied self is so far gone in the Cotard delusion that sufferers believe they do not exist, or that they are already dead. Of course, the experience that the self is unreal does not mean that any essence-of-self has upped and left. It just means that the control-oriented perceptions associated with the deepest layers of bodily regulation have gone significantly awry. (Location 3125)


> The beast machine theory accelerates the dissolution of this apparent mystery. By extending the controlled hallucination view to the very deepest layers of selfhood, by revealing the experience of the-self-as-really-existing as one more aspect of perceptual inference, the intuitions on which the hard problem implicitly rest are eroded even further. (Location 3136)


> In particular, the hard-problem-friendly intuition that the conscious self is somehow apart from the rest of nature – a really-existing immaterial inner observer looking out onto a material external world – turns out to be just one more confusion between how things seem and how they are. (Location 3138)


> The beast machine view of selfhood, with its intimate 194ties to the body, to the persistent rhythms of the living, returns us to a place liberated from conceits of a computational mind, before Cartesian divisions of mind and matter, reason and non-reason. What we might call the ‘soul’ in this view is the perceptual expression of a deep continuity between mind and life. It is the experience we have when we encounter the deepest levels of embodied selfhood – these inchoate feelings of ‘just being’ – as really existing. (Location 3143)


> We are not cognitive computers, we are feeling machines. (Location 3149)

- above re [[embodied intelligence project]]


> insular cortex: See Barrett & Simmons (2015) and Craig (2009) for more on the role of the insular cortex in interoception. (Location 3161)


> The core ideas were extended from 2015 onwards into the ‘beast machine’ theory of consciousness and self: Seth (2015a); Seth (2019a); Seth & Friston (2016); Seth & Tsakiris (2018). (Location 3173)


> must be a model: See Seth (2015a) and Seth & Tsakiris (2018) for more on the distinction between being a model and having a model. (Location 3190)


> beast machine theory: See Seth (2013), Seth (2014b), Seth (2015a), Seth (2019), Seth & Friston (2016), and Seth & Tsakiris (2018) for more technical 304versions of the beast machine theory and its components. The theory has many ancestors and influences, to which I cannot do full justice here. These include Thomas Metzinger’s philosophical examination of the self (Metzinger, 2003a), and the landmark accounts of predictive processing from Andy Clark and Jakob Hohwy (Clark, 2016; Hohwy, 2013). The theory owes a particular debt to other proposals of deep – but different – links between life, body, mind, and consciousness. Here, I have been strongly influenced by Antonio Damasio (e.g., 1994, 2010), Gerald Edelman (e. g., 1989), Karl Friston (e.g., 2010), Joe LeDoux (e.g., 2019), and Evan Thompson (e.g., 2014; see also Varela et al., 1993). For related ideas, see Panksepp (2005); Park & Tallon-Baudry (2014); Solms (2021); Metzinger’s concept of ‘existence bias’ (Metzinger, 2021), and the work of Lisa Feldman Barrett (e.g., 2017). (Location 3207)


> Sitting in between exteroception and interoception is proprioception, which refers to the perception of body position and movement (see chapter 5). It’s important not to confuse interoception with introspection, which refers to the internal examination of one’s own mental states. (Location 3237)


> What it means for something to exist is that there must be a difference – a boundary – between that thing and everything else. If there were no boundaries there would be no things – there would be nothing. (Location 3288)


> Living systems are different. Unlike the examples above, living systems actively maintain their boundaries over time – through moving, or sometimes even just through growing. They actively contribute to preserving themselves as distinct from their environment, and this is a key feature of what makes them living. The starting point for the FEP is that living systems, simply by virtue of existing, must actively resist the dispersion of their internal states. (Location 3296)


> All such systems tend towards disorder, towards a dispersion of their constituent states over time. The second law tells us that instances of organised matter, like living systems, are intrinsically improbable and unstable, and that – in the long run – we’re all doomed. (Location 3306)


> According to the FEP, for a living system to resist the pull of the second law it must occupy states which it expects to be in. Being a Good Bayesian, I’m using ‘expect’ in a statistical sense, not in a psychological sense. It is a very simple, almost trivial idea. (Location 3309)


> According to the FEP, this applies across the board. Ultimately, all organisms – not just bacteria – stay alive by minimising their sensory entropy over time, thereby helping to ensure that they remain in the statistically expected states compatible with survival. (Location 3327)


> A system cannot ‘know’ whether its own sensations are surprising, simply on the basis of the sensations themselves. (Here’s an analogy: is the number 6 surprising? It’s impossible to say, without knowing the context.) This is why sensory entropy is very different from things like levels of light, or concentrations of nearby nutrients, which can be directly detected by an organism through its senses, and used to guide behaviour. (Location 3332)


> These deep connections between the FEP and predictive processing make appealing sense. Intuitively, by minimising prediction error through active inference, living systems will naturally come to be in states they expect – or predict – themselves to be in. Seen this way, the ideas of predictive perception and controlled (or controlling) hallucination follow seamlessly from Friston’s ambitious attempt to explain the whole of biology. (Location 3348)


> Paraphrasing Friston, the view from the FEP is of organisms gathering and modelling sensory information so as to maximise the sensory evidence for their own existence. Or, as I like to say, ‘I predict myself therefore I am.’ (Location 3353)


> The role of the FEP can be understood as motivating and facilitating the interpretation of other, more specific theories; theories which are amenable to refutation by experiment. (Location 3368)

- Note above re [[embodied intelligence project]] and strategy for Jane's involvement

---
_reference:_ Seth, A. (2021) _Being You: A New Science of Consciousness_. London: Faber & Faber




