# Why Haidt and Schmidt’s Proposed Social Media Reforms Are Insufficient

![rw-book-cover](https://readwise-assets.s3.amazonaws.com/static/images/article4.6bc1851654a0.png)

## Metadata
- Author: [[Jon Haidt and Ravi Iyer from After Babel]]
- Full Title: Why Haidt and Schmidt’s Proposed Social Media Reforms Are Insufficient
- Category: #articles

## Highlights

> Rather than continue to apply the tools of social science to understand societal divisions, I decided to apply my skills more directly by working at Meta for over four years to help improve its products’ impact on society. I quickly learned that [content moderation was a band-aid rather than a long-term solution](https://substack.com/redirect/d8018ba7-93bb-43ff-afbb-7cce3e925eba?j=eyJ1IjoiYXZ6eDQifQ.G0OEO2hYU5EfmDn6Y1N-lMJfqyCMC6azYH_trtWPtnc) and that scalable progress required rethinking the *design* of Facebook’s core algorithms. ([View Highlight](https://read.readwise.io/read/01h4qg8qj6kmjkymrtw4xr5kct))


+++++ 
- Note: Harmful content


> Why did [publishers](https://substack.com/redirect/0a152b9f-c154-455f-b6b9-ca096e187c18?j=eyJ1IjoiYXZ6eDQifQ.G0OEO2hYU5EfmDn6Y1N-lMJfqyCMC6azYH_trtWPtnc) and [politicians](https://substack.com/redirect/1f5f8d1a-7985-4169-ad39-344516af61f8?j=eyJ1IjoiYXZ6eDQifQ.G0OEO2hYU5EfmDn6Y1N-lMJfqyCMC6azYH_trtWPtnc) tell us that social media platforms incentivized them to write more polarizing and sensational content? This was not a moderation issue, but a design flaw. There were areas where the platform’s design *actively incentivized* content and practices that led to more anger, distrust, and polarization. Naturally, if [borderline-harmful content was going to perform better](https://substack.com/redirect/c9ce655a-f63f-429a-a335-27cca25c910a?j=eyJ1IjoiYXZ6eDQifQ.G0OEO2hYU5EfmDn6Y1N-lMJfqyCMC6azYH_trtWPtnc) , it’s predictable that profit-seeking businesses and influence-seeking political organizations would respond to that incentive. ([View Highlight](https://read.readwise.io/read/01h4qg9yq1hgp94fh3te3tdbg4))


+++++ 
- Note: Harmful content


> With access to platform product experimentation data (reform #3), we could understand the causal impact of product decisions that platforms make and create clear design codes for platforms so that they don’t have to wonder what practices they will or will not be accountable for. Such design codes could be agreed upon by governments, states, school boards, parent groups, app stores, and advocacy organizations that all have a role in pressuring companies to build better, safer products. No enforcement mechanism will be airtight, but collective, specific pressure could help companies worry less about a competitor outcompeting them by building a more engaging product with the least amount of safety tools (e.g., optimized solely for time spent with no privacy defaults and no content provenance or user accountability functionality). ([View Highlight](https://read.readwise.io/read/01h4qhj2kva521xea3g92z0hzz))


+++++ 
- Note: Harmful content: thinking about the kind of “embodied” language that might emerge.

