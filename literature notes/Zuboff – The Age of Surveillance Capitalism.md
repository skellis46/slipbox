aliases: []
tags: [two-women-dancing]
author: Zuboff, Shoshana
year: 2019
title: The Age of Surveillance Capitalism: the Fight for the Future at the New Frontier of Power
type: literature
current-status: 
updated: "20210511"

# Zuboff – The Age of Surveillance Capitalism

### CHAPTER THREE: THE DISCOVERY OF BEHAVIORAL SURPLUS



- work w Shaun is at far far end of machine intelligence 

#### II. A Balance of Power

>Finally, people often say that the user is the “product.” This is also misleading, and it is a point that we will revisit more than once. For now let’s say that users are not products, but rather we are the sources of raw-material supply. As we shall see, surveillance capitalism’s unusual products manage to be derived from our behavior while remaining indifferent to our behavior. Its products are about predicting us, without actually caring what we do or what is done to us.


####  IV. The Discovery of Behavioral Surplus

>Google would no longer mine behavioral data strictly to improve service for users but rather to read users’ minds for the purposes of matching ads to their interests, as those interests are deduced from the collateral traces of online behavior. With Google’s unique access to behavioral data, it would now be possible to know what a particular individual in a particular time and place was thinking, feeling, and doing. That this no longer seems astonishing to us, or perhaps even worthy of note, is evidence of the profound psychic numbing that has inured us to a bold and unprecedented shift in capitalist methods.

>To state all this in plain language, Google’s invention revealed new capabilities to infer and deduce the thoughts, feelings, intentions, and interests of individuals and groups with an automated architecture that operates as a one-way mirror irrespective of a person’s awareness, knowledge, and consent, thus enabling privileged secret access to behavioral data.

>These capabilities were and remain inscrutable to all but an exclusive data priesthood among whom Google is the übermensch. They operate in obscurity, indifferent to social norms or individual claims to self-determining decision rights. These moves established the foundational mechanisms of surveillance capitalism.

#### VII. The Secrets of Extraction

>The intentional work of hiding naked facts in rhetoric, omission, complexity, exclusivity, scale, abusive contracts, design, and euphemism is another factor that helps explain why during Google’s breakthrough to profitability, few noticed the foundational mechanisms of its success and their larger significance. In this picture, commercial surveillance is not merely an unfortunate accident or occasional lapse. It is neither a necessary development of information capitalism nor a necessary product of digital technology or the internet. It is a specifically constructed human choice, an unprecedented market form, an original solution to emergency, and the underlying mechanism through which a new asset class is created on the cheap and converted to revenue. Surveillance is the path to profit that overrides “we the people,” taking our decision rights without permission and even when we say “no.” The discovery of behavioral surplus marks a critical turning point not only in Google’s biography but also in the history of capitalism.

#### VIII. Summarizing the Logic and Operations of Surveillance Capitalism

>This new market form declares that serving the genuine needs of people is less lucrative, and therefore less important, than selling predictions of their behavior. Google discovered that we are less valuable than others’ bets on our future behavior. This changed everything.

>The translation of behavioral surplus from outside to inside the market finally enabled Google to convert investment into revenue. The corporation thus created out of thin air and at zero marginal cost an asset class of vital raw materials derived from users’ nonmarket online behavior. At first those raw materials were simply “found,” a by-product of users’ search actions. Later those assets were hunted aggressively and procured largely through surveillance. The corporation simultaneously created a new kind of marketplace in which its proprietary “prediction products” manufactured from these raw materials could be bought and sold.

>We are no longer the subjects of value realization. Nor are we, as some have insisted, the “product” of Google’s sales. Instead, we are the objects from which raw materials are extracted and expropriated for Google’s prediction factories. Predictions about our behavior are Google’s products, and they are sold to its actual customers but not to us. We are the means to others’ ends.

>Industrial capitalism transformed nature’s raw materials into commodities, and surveillance capitalism lays its claims to the stuff of human nature for a new commodity invention. Now it is human nature that is scraped, torn, and taken for another century’s market project. It is obscene to suppose that this harm can be reduced to the obvious fact that users receive no fee for the raw material they supply. That critique is a feat of misdirection that would use a pricing mechanism to institutionalize and therefore legitimate the extraction of human behavior for manufacturing and sale. It ignores the key point that the essence of the exploitation here is the rendering of our lives as behavioral data for the sake of others’ improved control of us. The remarkable questions here concern the facts that our lives are rendered as behavioral data in the first place; that ignorance is a condition of this ubiquitous rendition; that decision rights vanish before one even knows that there is a decision to make; that there are consequences to this diminishment of rights that we can neither see nor foretell; that there is no exit, no voice, and no loyalty, only helplessness, resignation, and psychic numbing; and that encryption is the only positive action left to discuss when we sit around the dinner table and casually ponder how to hide from the forces that hide from us.

>Machine intelligence processes behavioral surplus into prediction products designed to forecast what we will feel, think, and do: now, soon, and later. These methodologies are among Google’s most closely guarded secrets. The nature of its products explains why Google repeatedly claims that it does not sell personal data. What? Never! Google executives like to claim their privacy purity because they do not sell their raw material. Instead, the company sells the predictions that only it can fabricate from its world-historic private hoard of behavioral surplus.

>Prediction products are sold into a new kind of market that trades exclusively in future behavior. Surveillance capitalism’s profits derive primarily from these behavioral futures markets.

>The new prediction systems are only incidentally about ads, in the same way that Ford’s new system of mass production was only incidentally about automobiles. In both cases the systems can be applied to many other domains. The already visible trend, as we shall see in the coming chapters, is that any actor with an interest in purchasing probabilistic information about our behavior and/or influencing future behavior can pay to play in markets where the behavioral fortunes of individuals, groups, bodies, and things are told and sold (see Figure 2).

### Chapter 4 THE MOAT AROUND THE CASTLE

#### I. Human Natural Resources

>In historian Karl Polanyi’s 1944 grand narrative of the “great transformation” to a self-regulating market economy, he described the origins of this translation process in three astonishing and crucial mental inventions that he called “commodity fictions.” The first was that human life could be subordinated to market dynamics and reborn as “labor” to be bought and sold. The second was that nature could be translated into the market and reborn as “land” or “real estate.” The third was that exchange could be reborn as “money.”3 Nearly eighty years earlier, Karl Marx had described the taking of lands and natural resources as the original “big bang” that ignited modern capital formation, calling it “primitive accumulation.”4

>The philosopher Hannah Arendt complicated both Polanyi’s and Marx’s notion. She observed that primitive accumulation wasn’t just a one-time primal explosion that gave birth to capitalism. Rather, it is a recurring phase in a repeating cycle as more aspects of the social and natural world are subordinated to the market dynamic. Marx’s “original sin of simple robbery,” she wrote, “had eventually to be repeated lest the motor of capital accumulation suddenly die down.”5

>Page grasped that human experience could be Google’s virgin wood, that it could be extracted at no extra cost online and at very low cost out in the real world, where “sensors are really cheap.” Once extracted, it is rendered as behavioral data, producing a surplus that forms the basis of a wholly new class of market exchange. Surveillance capitalism originates in this act of digital dispossession, brought to life by the impatience of over-accumulated investment and two entrepreneurs who wanted to join the system.

>Today’s owners of surveillance capital have declared a fourth fictional commodity expropriated from the experiential realities of human beings whose bodies, thoughts, and feelings are as virgin and blameless as nature’s once-plentiful meadows and forests before they fell to the market dynamic. In this new logic, human experience is subjugated to surveillance capitalism’s market mechanisms and reborn as “behavior.” These behaviors are rendered into data, ready to take their place in a numberless queue that feeds the machines for fabrication into predictions and eventual exchange in the new behavioral futures markets.

>In this future we are exiles from our own behavior, denied access to or control over knowledge derived from its dispossession by others for others. Knowledge, authority, and power rest with surveillance capital, for which we are merely “human natural resources.” We are the native peoples now whose tacit claims to self-determination have vanished from the maps of our own experience.

#### II. The Cry Freedom Strategy

>When asked his thoughts on how to limit “negativity” and increase “positivity,” Page reflected, “Maybe we should set aside a small part of the world… as technologists we should have some safe places where we can try out some new things and figure out what is the effect on society, what’s the effect on people, without having to deploy kind of into the normal world.”27

>It is important to understand that surveillance capitalists are impelled to pursue lawlessness by the logic of their own creation. Google and Facebook vigorously lobby to kill online privacy protection, limit regulations, weaken or block privacy-enhancing legislation, and thwart every attempt to circumscribe their practices because such laws are existential threats to the frictionless flow of behavioral surplus.28

#### III. Shelter: The Neoliberal Legacy

 >In the US, congressional statutes have played an equally or perhaps even more important role in sheltering surveillance capitalism from scrutiny. The most celebrated of these is a legislative statute known as Section 230 of the Communications Decency Act of 1996, which shields website owners from lawsuits and state prosecution for user-generated content. “No provider or user of an interactive computer service,” the statute reads, “shall be treated as the publisher or speaker of any information provided by another information content provider.”49 

>As one journalist put it, “To sue an online platform over an obscene blog post would be like suing the New York Public Library for carrying a copy of Lolita.”50

#### V. Fortifications

>Fortifications have been erected in four key arenas to protect Google, and eventually other surveillance capitalists, from political interference and critique: (1) the demonstration of Google’s unique capabilities as a source of competitive advantage in electoral politics; (2) a deliberate blurring of public and private interests through relationships and aggressive lobbying activities; (3) a revolving door of personnel who migrated between Google and the Obama administration, united by elective affinities during Google’s crucial growth years of 2009–2016; and (4) Google’s intentional campaign of influence over academic work and the larger cultural conversation so vital to policy formation, public opinion, and political perception.

>Both Google and Facebook currently lead aggressive state-level lobbying campaigns aimed at repelling or weakening statutes to regulate biometric data and protect privacy. As one report put it, “They want your body.”110

### CHAPTER FIVE THE ELABORATION OF SURVEILLANCE CAPITALISM: KIDNAP, CORNER, COMPETE

#### III. The Dispossession Cycle

##### Stage One: Incursion

>The firm wants to enable people to make better choices, but not if those choices impede Google’s own imperatives. Google’s ideal society is a population of distant users, not a citizenry. It idealizes people who are informed, but only in the ways that the corporation chooses. It means for us to be docile, harmonious, and, above all, grateful.

##### Stage Two: Habituation

##### Stage Three: Adaptation

##### Stage Four: Redirection

>Google discovered by chance or intention the source of every mapmaker’s power. The great historian of cartography, John B. Harley, said it succinctly: “Maps created empire.” They are essential for the effective “pacification, civilization, and exploitation” of territories imagined or claimed but not yet seized in practice. Places and people must be known in order to be controlled. “The very lines on the map,” wrote Harley, were a language of conquest in which “the invaders parcel the continent among themselves in designs reflective of their own complex rivalries and relative power.” The first US rectangular land survey captured this language perfectly in its slogan: “Order upon the Land.”72 The cartographer is the instrument of power as the author of that order, reducing reality to only two conditions: the map and oblivion. The cartographer’s truth crystallizes the message that Google and all surveillance capitalists must impress upon all humans: if you are not on our map, you do not exist.

#### VI. The Siren Song of Surveillance Revenues

>The Faustian pact that had been sold to the world’s internet users posed surveillance as the bitter price of free services such as Google’s Search and Facebook’s social network. This obfuscation is no longer tenable, as every consumer who pays his or her monthly telecom bill now also purchases the privilege of a remote and abstract but nevertheless rapacious digital strip search.

>As in the case of digital lenders, although a prospective tenant must formally “opt in” to the service, it is those who have less money and fewer options who are trapped in this Faustian bargain in which privacy is forfeit to social participation. “People will give up their privacy to get something they want,” celebrates the CEO of this service firm.

>I have suggested that the dangers of surveillance capitalism cannot be fully grasped through either the lens of privacy or of monopoly. In Chapter 6 I offer a new way of thinking about danger. The threats we face are even more fundamental as surveillance capitalists take command of the essential questions that define knowledge, authority, and power in our time: Who knows? Who decides? Who decides who decides?

### CHAPTER SIX: HIJACKED: THE DIVISION OF LEARNING IN SOCIETY

#### I. The Google Declarations

>According to the philosopher of language John Searle, a declaration is a particular way of speaking and acting that establishes facts out of thin air, creating a new reality where there was nothing. Here is how it works: sometimes we speak to simply describe the world—“you have brown eyes”—or to change it—“Shut the door.” A declaration combines both, asserting a new reality by describing the world as if a desired change were already true: “All humans are created equal.” “They are yours to command.” As Searle writes, “We make something the case by representing it as being the case.”3

- examining the declaration
- combine with "pro- or crypto-Nazi" from Baldwin commentary in drafts
- combine with Sennett "Together" on p.66 talking Hobbes' Leviathon

>As Searle concludes, “All of institutional reality, and therefore… all of human civilization is created by… declarations.”4
>Declarations are inherently invasive because they impose new facts on the social world while their declarers devise ways to get others to agree to those facts. Columbus’s declaration reflects this “conquest pattern,” as historian Matthew Restall writes:

dress as a conquistador (see text in book after above)
and there could be a beanbag


>Surveillance capitalism succeeded by way of aggressive declaration, and its success stands as a powerful illustration of the invasive character of declarative words and deeds, which aim to conquer by imposing a new reality. 

#### II. Who Knows?

>Any consideration of the division of learning must resolve these dilemmas expressed in three essential questions. The first question is “Who knows?” This is a question about the distribution of knowledge and whether one is included or excluded from the opportunity to learn. The second question is “Who decides?” This is a question about authority: which people, institutions, or processes determine who is included in learning, what they are able to learn, and how they are able to act on their knowledge. What is the legitimate basis of that authority? The third question is “Who decides who decides?” This is a question about power. What is the source of power that undergirds the authority to share or withhold knowledge?

>Information scholar Martin Hilbert and his colleagues observe that even the foundational elements of civilization, including “language, cultural assets, traditions, institutions, rules, and laws… are currently being digitized, and for the first time, explicitly put into visible code,” then returned to society through the filter of “intelligent algorithms” deployed to govern a rapidly multiplying range of commercial, governmental, and social functions.16 The essential questions confront us at every turn: Who knows? Who decides? Who decides who decides?


#### IV. The New Priesthood

>In Britain, university administrators are already talking about a “missing generation” of data scientists. The huge salaries of the tech firms have lured so many professionals that there is no one left to teach the next generation of students. As one scholar described it, “The real problem is these people are not dispersed through society. The intellect and expertise is concentrated in a small number of companies.”32

>Under the regime of surveillance capitalism, the corporation’s scientists are not recruited to solve world hunger or eliminate carbon-based fuels. Instead, their genius is meant to storm the gates of human experience, transforming it into data and translating it into a new market colossus that creates wealth by predicting, influencing, and controlling human behavior.

>More than six hundred years ago, the printing press put the written word into the hands of ordinary people, rescuing the prayers, bypassing the priesthood, and delivering the opportunity for spiritual communion directly into the hands of the prayerful. We have come to take for granted that the internet enables an unparalleled diffusion of information, promising more knowledge for more people: a mighty democratizing force that exponentially realizes Gutenberg’s revolution in the lives of billions of individuals. But this grand achievement has blinded us to a different historical development, one that moves out of range and out of sight, designed to exclude, confuse, and obscure. In this hidden movement the competitive struggle over surveillance revenues reverts to the pre-Gutenberg order as the division of learning in society shades toward the pathological, captured by a narrow priesthood of privately employed computational specialists, their privately owned machines, and the economic interests for whose sake they learn.

^2369f0

#### V. The Privatization of the Division of Learning in Society

#### VI. The Power of the Unprecedented: A Review

>the twenty-first century finds surveillance capital pitted against the entirety of our societies, right down to each individual member. The competition for surveillance revenues bears down on our bodies, our homes, and our cities in a battle for power and profit as violent as any the world has seen. Surveillance capitalism cannot be imagined as something “out there” in factories and offices. Its aims and effects are here… are us.

>These operations challenge our elemental right to the future tense, which is the right to act free of the influence of illegitimate forces that operate outside our awareness to influence, modify, and condition our behavior. We grow numb to these incursions and the ways in which they deform our lives. We succumb to the drumbeat of inevitability, but nothing here is inevitable. Astonishment is lost but can be found again.

## PART II THE ADVANCE OF SURVEILLANCE CAPITALISM

### CHAPTER SEVEN THE REALITY BUSINESS

#### I. The Prediction Imperative

>Schmidt was, in fact, merely paraphrasing computer scientist Mark Weiser’s seminal 1991 article, “The Computer for the 21st Century,” which has framed Silicon Valley’s technology objectives for nearly three decades. Weiser introduced what he called “ubiquitous computing” with two legendary sentences: “The most profound technologies are those that disappear. They weave themselves into the fabric of everyday life until they are indistinguishable from it.” 

>There are many buzzwords that gloss over these operations and their economic origins: “ambient computing,” “ubiquitous computing,” and the “internet of things” are but a few examples. For now I will refer to this whole complex more generally as the “apparatus.” Although the labels differ, they share a consistent vision: the everywhere, always-on instrumentation, datafication, connection, communication, and computation of all things, animate and inanimate, and all processes—natural, human, physiological, chemical, machine, administrative, vehicular, financial. Real-world activity is continuously rendered from phones, cars, streets, homes, shops, bodies, trees, buildings, airports, and cities back to the digital realm, where it finds new life as data ready for transformation into predictions, all of it filling the ever-expanding pages of the shadow text.4

>Under this regime, ubiquitous computing is not just a knowing machine; it is an actuating machine designed to produce more certainty about us and for them.


#### V. Certainty for Profit

>“Ultimately, IoT’s true value depends on customers adjusting their behaviors and risk profiles based on feedback from their ‘things.’”42 Health insurers are another target: “Wearable accelerometers” could “improve traceability of their compliance” with prescribed exercise regimes, and “digestible sensors” could track compliance with dietary and medication schedules, “providing higher truth and better granularity than a monthly refill.”43

#### VI. Executing the Uncontract

>So let us establish our bearings. What Varian celebrates here is not a new form of contract but rather a final solution to the enduring uncertainty that is the raison d’être of “contract” as a means of “private ordering.” In fact, the use of the word contract in Varian’s formulation is a perfect example of the horseless-carriage syndrome. Varian’s invention is unprecedented and cannot be understood as simply another kind of contract. It is, in fact, the annihilation of contract; this invention is better understood as the uncontract.
>The uncontract is a feature of the larger complex that is the means of behavioral modification, and it is therefore an essential modality of surveillance capitalism. It contributes to economies of action by leveraging proprietary behavioral surplus to preempt and foreclose action alternatives, thus replacing the indeterminacy of social processes with the determinism of programmed machine processes. This is not the automation of society, as some might think, but rather the replacement of society with machine action dictated by economic imperatives.
>The uncontract is not a space of contractual relations but rather a unilateral execution that makes those relations unnecessary. The uncontract desocializes the contract, manufacturing certainty through the substitution of automated procedures for promises, dialogue, shared meaning, problem solving, dispute resolution, and trust: the expressions of solidarity and human agency that have been gradually institutionalized in the notion of “contract” over the course of millennia. The uncontract bypasses all that social work in favor of compulsion, and it does so for the sake of more-lucrative prediction products that approximate observation and therefore guarantee outcomes.
>This substitution of machine work for social work is possible thanks to the success of Google’s declarations and the road that Google paved for surveillance capitalists’ dominance of the division of learning. Sitting in the catbird seat, Google can observe what was previously unobservable and know what was previously unknowable. As a result, the company can do what was previously undoable: bypass social relations in favor of automated machine processes that compel the behaviors that advance commercial objectives. When we celebrate the uncontract, as Varian and others do, we celebrate the asymmetries of knowledge and power that produce these new possibilities. The uncontract is a signpost that reminds us of our bearings as we follow the next sections of this chapter toward a clearer picture of surveillance capitalism’s growing ambitions in the annexation of “reality” to its kingdom of conquered human experience.

#### VII. Inevitabilism

>Silicon Valley is the axis mundi of inevitabilism. Among high-tech leaders, within the specialist literature, and among expert professionals there appears to be universal agreement on the idea that everything will be connected, knowable, and actionable in the near future: ubiquity and its consequences in total information are an article of faith.

>And later, “The collective benefit of sharing human knowledge and creativity grows at an exponential rate. In the future, information technology will be everywhere, like electricity. It will be a given.”

>Despite its pervasiveness both in Silicon Valley and in the wider culture of data scientists and technology developers, inevitabilism is rarely discussed or critically evaluated. Paradiso’s conception of a “digital omniscience” is taken for granted, with little discussion of politics, power, markets, or governments. As in most accounts of the apparatus, questions of individual autonomy, moral reasoning, social norms and values, privacy, decision rights, politics, and law take the form of afterthoughts and genuflections that can be solved with the correct protocols or addressed with still more technology solutions. If information will stream “directly into our eyes and ears” and “the boundaries of the individual will be very blurry,” then who can access that information? What if I don’t want my life streaming through your senses? Who knows? Who decides? Who decides who decides? The answers to such questions are drowned in the thrum of all things continuously illuminated, registered, counted, controlled, and judged.

>A senior systems architect laid out the imperative in the clearest terms: “The IoT is inevitable like getting to the Pacific Ocean was inevitable. It’s manifest destiny. Ninety-eight percent of the things in the world are not connected. So we’re gonna connect them. It could be a moisture temperature that sits in the ground. It could be your liver. That’s your IoT. The next step is what we do with the data. We’ll visualize it, make sense of it, and monetize it. That’s our IoT.”

#### VIII. Men Made It

>Every doctrine of inevitability carries a weaponized virus of moral nihilism programmed to target human agency and delete resistance and creativity from the text of human possibility. Inevitability rhetoric is a cunning fraud designed to render us helpless and passive in the face of implacable forces that are and must always be indifferent to the merely human. This is the world of the robotized interface, where technologies work their will, resolutely protecting power from challenge.

>This theme of supposed technological autonomy is a venerable one among technology scholars. Langdon Winner again proves to be a worthy guide when he reminds us that an unquestioning acceptance of technology has become a feature of modern life: “The changes and disruptions that an evolving technology repeatedly caused in modern life were accepted as given or inevitable simply because no one bothered to ask whether there were other possibilities.”70

>Inevitabilism precludes choice and voluntary participation. It leaves no room for human will as the author of the future. This raises questions: At what point does inevitabilism’s claim to ubiquitous extraction and execution shade into abuse?

- workshop
and this:

Who knows? Who decides? Who decides who decides?


### CHAPTER NINE RENDITION FROM THE DEPTHS

#### I. Personalization as Conquest

>This is a new frontier of behavioral surplus where the dark data continent of your inner life—your intentions and motives, meanings and needs, preferences and desires, moods and emotions, personality and disposition, truth telling or deceit—is summoned into the light for others’ profit. The point is not to cure but to render all of it as immeasurably tiny bits of behavior available for calculation so that each can take its place on the assembly line that moves from raw materials to product development, manufacturing, and sales.

>Online and offline behavioral surplus—your e-mail content, where you went this afternoon, what you said, what you did, how you felt—are combined into prediction products that can serve an emerging marketplace in which every aspect of your daily reality is up for bid.

>In this commercial dreamscape, words that were once conceived of as “behind closed doors” are eagerly rendered as surplus. These new supply operations convert your talk into behavior for surplus in two ways. The first derives from what you say, the second from how you say it. Smart-home devices such as Amazon’s Echo or Google Home render rivers of casual talk from which sophisticated content analyses produce enhanced predictions that “anticipate” your needs. 

>There was a time when you searched Google, but now Google searches you. Advertisements for Google Home feature loving families leading busy, intricate lives but visibly relieved to return home and fall into the arms of this omniscient, efficient caretaker. This second-modernity dream come true extracts an unusually high tax for its promise of a more effective life. For each user to have his or her own individual Google, as Pichai envisions, Google must have each individual.18

>There are differences among the various incarnations of “personalization” and “assistance” offered by the tech giants, but these are trivial compared with the collective urge toward total knowledge—about your inner states, real-world context, and specific daily life activities—all in the service of successfully training the machines that they might better target market operations to each moment of life.

>In pursuit of the what and the how of voice surplus, the logic of competition is to corner as much supply as possible. The urge toward totality generates competitive pressures to become the run time and the new interface: the dominant, if not exclusive, medium through which we access and engage the apparatus as it engages us. It’s a race to corner all the talk as a prerequisite for achieving the privileged status of the One Voice, which will bestow upon the winner the ability to anticipate and monetize all the moments of all the people during all the days.

#### II. Rendition of the Self

>Personality analysis for commercial advantage is built on behavioral surplus—the so-called meta-data or mid-level metrics—honed and tested by researchers and destined to foil anyone who thinks that she is in control of the “amount” of personal information that she reveals in social media. In the name of, for example, affordable car insurance, we must be coded as conscientious, agreeable, and open. This is not easily faked because the surplus retrieved for analysis is necessarily opaque to us. We are not scrutinized for substance but for form. The price you are offered does not derive from what you write about but how you write it. It is not what is in your sentences but in their length and complexity, not what you list but that you list, not the picture but the choice of filter and degree of saturation, not what you disclose but how you share or fail to, not where you make plans to see your friends but how you do so: a casual “later” or a precise time and place? Exclamation marks and adverb choices operate as revelatory and potentially damaging signals of your self.

>[Billionaires such as Zuckerberg and Mercer] ... They aim to be unchallenged in their power to know, to decide who knows, and to decide who decides. 

#### III. Machine Emotion

#### IV. When They Come for My Truth

>I want to deliberately sidestep a more detailed discussion of what is “personality” or “emotion,” “conscious” or “unconscious,” in favor of what I hope is a less fractious truth thrown into relief by this latest phase of incursion. Experience is not what is given to me but rather what I make of it. The same experience that I deride may invite your enthusiasm. The self is the inward space of lived experience from which such meanings are created. In that creation I stand on the foundation of personal freedom: the “foundation” because I cannot live without making sense of my experience.

>No matter how much is taken from me, this inward freedom to create meaning remains my ultimate sanctuary. Jean-Paul Sartre writes that “freedom is nothing but the existence of our will,” and he elaborates: “Actually it is not enough to will; it is necessary to will to will.”117 This rising up of the will to will is the inner act that secures us as autonomous beings who project choice into the world and exercise the qualities of self-determining moral judgment that are civilization’s necessary and final bulwark. This is the sense behind another of Sartre’s insights: “Without bearings, stirred by a nameless anguish, the words labor.… The voice is born of a risk: either to lose oneself or win the right to speak in the first person.”118

>Surveillance capital wants more than my body’s coordinates in time and space. Now it violates the inner sanctum as machines and their algorithms decide the meaning of my breath and my eyes, my jaw muscles, the hitch in my voice, and the exclamation points that I offered in innocence and hope.

>I don’t quite know whether it is especially computer science or its sub-discipline Artificial Intelligence that has such an enormous affection for euphemism. We speak so spectacularly and so readily of computer systems that understand, that see, decide, make judgments… without ourselves recognizing our own superficiality and immeasurable naiveté with respect to these concepts. And, in the process of so speaking, we anesthetize our ability to… become conscious of its end use.… One can’t escape this state without asking, again and again: “What do I actually do? What is the final application and use of the products of my work?” and ultimately, “Am I content or ashamed to have contributed to this use?”122 -- Joseph Weizenbaum


### Chapter Ten: Make Them Dance

#### I. Economies of Action




