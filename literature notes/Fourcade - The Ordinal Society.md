---
aliases: []
tags: []
type: "literature"

---

# Fourcade - The Ordinal Society

_previous note:_ [[technology and individualism]]

An ordinal society creates order through automated ranking and matching. The apparent power of its methods justifies the ostensible rightness of its hierarchies and categories.


The hacker myth expanded to offer a path toward a kind of transcendence, toward what Vincent Mosco called “the digital sublime.”


Unprofitable lines of business in search, in chat, in social interactions, and many other places could be repurposed by taking advantage of the digital traces people left behind on their own computers and the servers they connected to. Companies breathed in the exhaust fumes of their own data and found that it smelled of money.


In 2021, former Wired magazine editor and flying robots company CEO Chris Anderson asserted on Twitter, “Ask forgiveness, not permission” is the guiding motto of Silicon Valley. That means innovating in the regulatory “gray space” between the obviously allowed (too crowded) and the obviously illegal. Think AirBnB, Uber or even our open source drones, which … all found loopholes or ambiguity in existing regs to introduce something new, which then proved too popular to shut down.


For the region’s “technological solutionists,” disregard for legal rules, hierarchies of knowledge, and existing organizational forms was the price of progress.26


While the new revolution was made of code rather than coal, scripts rather than steam, its language and imagery was curiously and inescapably industrial. Code was made, it seemed, in forges, with engines, through pipelines, by foundries—an entire metaphorical world of intensely physical production was conjured up to represent the activities of people who spent their days in front of screens, typing.


“Real power,” Mosco reminds us, is achieved when a technology “[leaves] mythology and [enters] banality.”33


A stew of intimate convictions and personal “research” underpins the process of knowledge production and belief formation.


As companies like Facebook grew to reach billions of people, they found themselves with direct access to both very large quantities of data about individual users and the ability to produce a detailed, “network’s-eye” view of the social whole. In a prophetic text, Gilles Deleuze has argued that this kind of infrastructure expresses a distinctive conception of power. Unlike institutionalized “spaces of enclosure” such as prisons, schools, or factories, “spaces of control” are distributed and connected through technical gateways and standards. Movement from one space to another may require some kind of authentication, so they are not entirely open. But people move through them smoothly. The kind of power deployed in such spaces, Deleuze suggests, is not about directly “molding” people but about “modulating” action at a finely detailed level through continuous adaptation and feedback loops. That is to say, control is accomplished cybernetically rather than mechanically.48 Rather than governing by directly disciplining populations, these systems sense and react to the actions of individuals going about their day. We can also see this is an extension of the liberal injunction to exert power through freedom, and specifically through “the mechanisms of the market and the imperatives of self-realization.”49


Still, the real advances in information technology have been economically transformational, and the idea of automation remains culturally compelling. As they project into the future, the thought leaders of capitalism need more than numbers. They demand stories, fiction, narratives—in other words, belief.60


The broader historical context was a change in the nature of capitalism itself. After the top-down standardization of the Fordist era, network technologies seemed to offer a means to fulfill a yearning for personal authenticity and emancipation.63


These changes have been overwhelming and strange. In a few decades we moved from a quirky protocol for sharing documents to a system of organization, evaluation, and control that is remarkably convenient, often delightful, and at times frightening. It is on the point of encompassing our lives. Understanding the structure of this new society is the task of this book.


Social theorists underestimate the power of delight. When a technology can deliver that experience—again, whether in the service of something “useful” or simply for its own sake—people really love it. They will seek it out. They will show and tell it to their friends. The instinct of the critic is to say that this delight is misleading or illusory.


The world is always being made a worse place, not a better one. But—also like a mirror—these critiques do not reverse up and down. The technology is still assumed to work as claimed, even though in practice it may be buggy or broken most of the time. Thus, while the temperament of theory is critical, a fundamental belief in the propulsive power of technological change still lives in its marrow. The algorithms and the science behind them are assumed to work. It is just that their effects are, in truth, malign. The task of theory from this perspective is to expose that malignancy.


Even the vocabulary used by social scientists suggests a deep ambivalence. Writing in 1952, the sociologist Howard Becker noted that we use the word datum rather than captum for the elemental unit of evidence. The former is the Latin past participle of dare, “to give”; the latter, the past participle of capere, “to take.” Becker thought this an “unfortunate accident of history” because “all data are in some sense capta, for nothing is given unless it is simultaneously taken.”


At its heart big data is “big capta.” There have been occasional efforts to express this idea more explicitly, if uncritically.


We are left with a field of oppositions that, even if they do not rise to the level of true paradox, remain at least puzzling. In everyday use, software makes previously impossible things easy but remains riddled with irritations and failures. The industry that produces it is intensely competitive, but large parts of it rest on a foundation of open-source tools. Platforms accumulate users and profits but seem to give away many of their products for free. Surveillance and tracking in the service of monetization is pervasive, but people irrepressibly share things with one another and with the platforms. How can so much be taken through the process of giving?


The strange power of the gift lies in the “initiating” or creative character of the first “free” act of giving and in the instability and intrinsic ambiguity of subsequent exchanges.


Gift exchange has an intrinsically hazy or fuzzy character that allows both for clear calculation and a kind of plausible obfuscation.8 Its continuity through time puts it at the core of ordinary social relations. Meeting the obligation to return or reciprocate what one has received, in some appropriate form and at some appropriate moment, is what makes gift giving a social relationship. Indeed, that sort of activity is what an actually existing, ongoing social relationship is. There is nothing more to it.


the long history of scholarship on gift exchange in anthropology and sociology makes it clear that gifts and reciprocity create social and economic dependency just as surely as market exchanges.


Indeed, pure market transactions mediated by money can be thought of as an effort to make exchanges happen in a way that escapes the tendrils of the gift, that avoids the tendency of gift giving to draw transactors into ongoing cycles of obligatory transfers with all their attendant spillovers and duties.


But particular gift exchanges express and encompass social relationships as a whole, making the elements of politeness, deference, honor, and obligation far more than simply empty ceremony.


Economists typically treat the issue as one of cost-benefit analysis. By one estimate, the median user in the late 2010s would have had to be paid over $17,530 to give up search for a year, $1,173 to give up YouTube, and $576 to give up Facebook.13 If each person, individually, gets a lot more value out of Facebook or Google than Facebook or Google gets out of them, then it is not worth sweating over.


the successful implementation, by platforms like YouTube, of bot-driven “copystrike” methods that continuously monitor uploads for copyright violations and automatically remove unauthorized material.


In a similar way, the constant flux of social life, the flow of things given in everyday reciprocation, does not naturally exist in the form of bundles of enforceable rights, in legal claims over tangible goods or services, or in measured and analyzable datasets. It is simply what people do, as easy as breathing. The idea that one could in some sense capture and represent this flow—not just every song, but every greeting, every friendly chat, every disagreement, every joke, every frown or smile, every small bit of social existence—seemed, until recently, like a fantasy.


This was sometimes characterized as a transition from “information silos,” or networks of sites that are formally connected but substantively isolated, to “architectures of participation.”33 The wave of what later came to be called social media began in earnest.


From an economic point of view, this flow of human interaction and creative activity is a little like the energy of the sun: it floods across the earth continuously and in vast quantities. Only a tiny fraction of it is captured in a way that is both formally measurable as economic activity and transformed into something financially profitable.


It is important to understand the reciprocal character of this process. In the language of gift exchange, these “things given” do not give themselves, since they have no materiality outside the physical bodies that “produce” them. Instead, human activities must be reconfigured so they become an abstract, information- (and money-) producing process, what McKenzie Wark calls a “hack.”36 The hack is relational and participatory, using design infrastructures to exploit various aspects of human desperation and spontaneity: the critical need to make money, the desire to belong, the ambition to compare favorably.


That Facebook might now know what people are literally praying for seems like something from a ham-fisted dystopian novel. But it is not that people are “forced” to tell Facebook their prayers, or that it “colonized” or “appropriated” those activities. Often, users introduce wider aspects of sociality and social practice into this world, and then the company realizes this is a behavior that might be fashioned into something more delimited, organized, data-generating, and ultimately profitable: something that can generate a manageable order, fit for an algorithm to digest, analyze, and sell to advertisers.


As it grew, Facebook’s leadership became increasingly eager to discover what, if anything, might define the upper limit of users’ willingness to feed large quantities of mundane but intrinsically relational data to it. More than any of the present-day giants of information technology, Facebook accommodated and then egged on people’s social and creative impulses—their willingness to freely give, freely connect, freely produce, and freely exchange with one another—while also converting that tendency into profit.


Then firms have to deal with the general problems that come with controlling any large population of people, at the limit facing the problems of government itself. The thrill of engagement becomes the madness of crowds. And yet, people keep coming back. Sociality is hard to live with but impossible to leave altogether.


When gathering and then storing data in huge volumes is routine, it becomes impossible to imagine such a resource remaining untouched or fully encapsulated indefinitely.


Instead the accumulation of excess continues, and with it the expectation that it will be in some way expended.


Indeed, the practice of data collection and recordkeeping reaches back to the origins of literacy and the emergence of the state itself.7 It is almost coextensive with what is formal about formal organization. We can certainly find plenty of early examples of recordkeeping and accounting across the earliest settled societies. But the systematization of numerical thinking as a technology of truth and administration is more recent.


The nineteenth-century statistical revolution further elaborated on this moral promise by turning numbers into what Theodore Porter called “technologies of distance,” to be deployed in heavily politicized contexts to create an aura of impartiality, certainty, and finality.


Frank and Lillian Gilbreth used the best technology then available—film cameras—to observe and record the work process in order to understand and reorganize its component parts.23


The Hollerith card “would become an essential tool for making the world legible to governments and corporations.”27 But it also expanded what was possible, as it dramatically increased the volume and detail of data that could be collected on anything and anyone. It did not simply act as a means of recording what was already there. It allowed new things to be done. It was an engine, not a camera.


The real achievement was naturalizing the idea that the long-term profitability of organizations depends on the collection and exploitation of data. This notion, which we call “the data imperative,” was a cultural and political accomplishment, beyond the economically driven search for efficiency.


Like people, institutions observe each other, fear missing out on the hype, and strive to enact the scripts available in their field.


Science and technology, Max Weber remarked, are “chained to the course of progress.”36 They contain within themselves the principle of their own inexorable movement forward. That principle, or the notion that everything can be mastered by calculation, Weber calls “intellectualization” and “disenchantment.”


But in practice, data collection often has a ceremonial character, just as Meyer and Rowan predicted. Professional exhortations; conventional wisdom; falling computing and storage costs; and most recently the gigantic training demands of large language models for content production—all of these forces have pushed organizations to sweep up increasingly large quantities of bits about whatever crosses their path. “Thou shalt gather data” has become second nature for private and public institutions alike.


The assumption is that it will, somehow, eventually be useful or valuable at some economically justifiable cost.


At the center of any data infrastructure is what Robert Kitchin calls “indexical data”—data that “enable identification and linking across files … unique identifiers, such as passport and social security numbers, credit card numbers, manufacturer serial numbers, digital object identifiers, IP [network node] and MAC [hardware device] addresses, order and shipping numbers, as well as names, addresses, zip codes.”37


Commentators often speak blandly of “digital natives” as if they had a natural technical facility with computing. The reality of the idea may lie more in the tendency to accept a social ecology where everything is indexed, tracked, and measured.


Organizations share this attitude, too, as advances in ML have solidified “the unnerving belief that everything is data and is there for the taking.”57


Meanwhile, in many applied settings, prediction trumps everything else, with causal attribution or explanation following along some way behind. It is in these settings that the feedback between effective prediction and presumptive causality can start to loop in ways that are counterproductive.


Perhaps substantively meaningless correlations are taken at face value to determine important decisions, or overfitted models are used in ways that would embarrass any well-trained analyst, or a method requiring any number of careful assumptions is put to work on terrible data.67


The kind of learning that takes place when the aim is to accurately predict is different from the kind of learning focused on the real structure of social processes. The kinds of knowledge generated are correspondingly different also.


Arthur C. Clarke’s third law of prediction is, famously, “Any sufficiently advanced technology is indistinguishable from magic.” The kind of technology Clarke had in mind was one that truly works, but in such a sophisticated way that it is entirely opaque to the ordinary people who use it.


Our machines classify because people do. We come to know and relate to the world by way of categories. To be human is to be able to recognize patterns and distinguish things according to type.


We refer to things through sounds and words, and we attach ideas to them that we call concepts. Some of our categories remain tacit; others are explicitly governed by custom, law, politics, or science. The application of category systems for the same things varies by context and in use.


Independent of whether they “carve nature at the joints,” as philosophers like to say, what gives categories their authority—what makes them appear natural to us—is the fact that they are collectively crafted, sustained, and enforced.


The most basic insight of sociology is that the joint action of human beings produces a social world that has the character of objective fact.


Social classifications are entrenched in people’s emotions, in their bodies, and in their everyday practices. This makes them hard to change.


Since some social categories are advantageous and others detrimental, people struggle over their definition. They press to be fitted into one type rather than another.4 They come up with new categories. In Ian Hacking’s felicitous phrase, people are “made up” and remade all the time that way. New concepts come along to identify with and be identified by.


More deeply, present-day liberal democracies tend to have a “politics of recognition” that accords moral importance to ideas of self-categorization, personal authenticity, and dignity. This makes it easier for many formerly primordial categories and classes to be contested.6 It also makes possible the sort of entrenchment and sacralization that is distinctively modern, centered on the individual.


Analytics tools begin the work of arranging longitudinal and cross-sectional profiles and disaggregating and sorting these “data doubles” into predicted categories.7 While you exist as a physical person in the world, your data double is the representation of you, your tastes, and your actions that can be reconstructed in whole or in part from the records and traces you leave behind.


The categorical systems themselves may vary depending on the purpose at hand—people may be sorted into types of person, market segments, risk brackets, expected value targets, and more. But what unites these systems is that they are actionable. Writing about market research in the early 1990s, Oscar Gandy Jr. called this now ubiquitous process “the panoptic sort”:


As this “cybernetic triage” unfolds,9 the analysis of tracked and classified behaviors forms the basis of differential treatment, thus affecting social stratification through the allocation of similar sets of opportunities to similarly situated people—what sociologists since Max Weber have called “life chances.”


Often these categories are not—or sometimes, as a matter of law, cannot be—constructed from standard demographic classifications such as race and gender. Instead they tend to be behavioral and probabilistic, predicting the likelihood that people will do or like certain kinds of things, or the position they may reach on a particular scale. In that sense these methods construct a “postdemographic” classificatory infrastructure.10


Ordinal classifications, meanwhile, are explicitly organized by measures of position, priority, or value along some countable dimension.


From the point of view of social order, the most basic kinds of processes are those of nominalization and ordinalization: the naming of kinds and the designation of ranks.


Insofar as they are about distinguishing better from worse, as opposed to simply affirming the uniqueness of every single thing in the world, qualitative modes of classification can be as powerfully disciplining as quantitative ones.


the significance of what John Cheney-Lippold calls the “right of the algorithm” and what Amoore calls the “deep border” of ML, may supplement and even supersede national citizenship and the physical border.24 The analogically derived certainty of belonging somewhere may be shattered by one’s place in a dataset and the inferences made from it.


Following the work of Pierre Bourdieu, social theorists and researchers have named many forms of “capital” over the past forty years—absurdly many, perhaps. Do we really need another sort? There is human capital, economic capital, cultural capital, social capital, bodily capital, and more besides. Each type begins with the same initial idea.


His theory of practice tried to get a grip on how people’s class position organized or structured their tendency to speak or act in particular ways, to develop some tastes rather than others, and to think they were “cut out” for some kinds of work while not even considering some alternatives as possibilities. Bourdieu’s concept for the individual’s experience of this process is a notoriously slippery one: the “habitus.” This is the “feel for the game” or “sense of the rules” that you carry around with you.


When a situation feels comfortable or a decision feels like the right thing to do, the habitus is the feeling in your gut that grounds that experience.


It is the process of generating the apparently “unbought grace of life” that fascinated Bourdieu.


In Bourdieu’s picture, this process mostly happens during the long period of formal education. It takes money and, above all, time—two resources that not everyone has in equal measure. One kind of capital, the straightforward monetary kind, is slowly converted into another, the cultural kind. Education gives you public credentials, certainly. In Bourdieu’s terms, this is the “institutionalized” form that cultural capital takes. But it also gives you “embodied” cultural capital that you express without needing to show people your college diploma.


But there is also something deeply true about the insight that the organization of the outside world, with all its unequally distributed resources and often obscure rules, gets inside people in a way that makes life go more smoothly for some than for others.


Bourdieu’s analysis of the forms of capital and their role in social reproduction can be seen as an effort, well before its time, to theorize the now ubiquitous concept of “privilege.”


Eigencapital is a little different. It has its origins in particulars—in the totality of one’s interactions with the digital economy—but it has a generalized, relational character that is not found in the usual list of novel forms of capital.


“The distribution of waiting time,” Barry Schwartz remarks, “coincides with the distribution of power.”


As the physical world fills with sensors, and people live increasingly hybrid lives, resisting these expectations is hard in practice. Furthermore, it is not necessarily desirable: being invisible to digital infrastructures is suspicious, and organizations code it negatively. The failure to engage and properly care for one’s data double is a moral fault at best, a sure sign of illicit behavior at worst.33


For now we can say that people who are inactive are of little value to organizations. They are expensive to know and unprofitable to manage. By the systems’ standards, they perform poorly. And so they get punished for it. Likewise, public institutions also increasingly operate according to a logic that privileges electronic visibility: the extension of rights depends on digital incorporation and the steady production of data about oneself.


Far from being passive, they are emotionally involved in systems of data production and management and sometimes take great pains to develop strategies that “feel right”—or properly balance the need to be visible with the desire, however hopeless, to safeguard their privacy.35


Knowledge of transactions and assets had been a kind of data, but now data became a kind of asset.


The new business wisdom was encapsulated in a metaphor that quickly became a cliché. This was the idea that “data is the new oil.”


When these technologies are embedded everywhere and everyone is surveilled in this way, insurance premiums will depend on the specific risk profile as measured and scored by the sensing algorithm. But what remains of the purpose of insurance—to socialize risk—when everyone pays the price they “deserve”?


This may not be so bad where car insurance is concerned,58 but in other domains, such as health or place of residence, the most significant sources of risk—and thus the proper allocation of responsibility—may lie outside the individual in the natural or social environment. The fact that these structural forces cannot easily be measured does not mean that they can be conveniently ignored. Doing so not only excludes people unfairly but also threatens the way that insurance systems can act as a prosaic but intensely practical manifestation of solidarity.


In this way, every producer of goods becomes a technology company, every technology company becomes a service provider, and every useful service becomes a stream of data that can be turned into an asset.


It is also a source of information about what is happening—and what is likely to happen—in various crop markets in the aggregate. Thus, in virtue of collecting data on how its machinery is being used, a manufacturer might end up, directly or indirectly, in the business of agricultural futures, either using this new information itself or selling it on to firms that can make better use of it. This might leave the firm in a situation where it hopes to profit from investment decisions or general price movements in markets that adversely affect the very customers it sells its equipment to, and from whom it collects data.


A car ride via Uber, a sorting task on Amazon’s Mechanical Turk, a microcontract with a vendor, or any one of many other kinds of labor become what Veena Dubal calls “digital piecework.”10 The same process of fine-grained standardization applies to personal data harvested from multiple sources. This is the “workless labor” of users, in Ori Schwarz’s felicitous phrase.


Modern finance is electronic. It not only depends upon but fundamentally just is the protocols or conventions governing the treatment, formatting, recording, and circulation of data within a network.


For some commentators, the present wave of speculation is more than just a familiar convulsion of a market gone wild. Mark Andrejevic argues, for example, that the universalization of predictive capacity has primed the “full range of social and political life” for speculative activity.30 Similarly—though the specifics of their arguments vary—Laura Bear, Michel Feher, and Aris Komporous-Athanasiou all see speculation writ large as the episteme of our time.31 It seems to be the natural condition of an economy dominated by increasingly global, increasingly rapid, and increasingly open circuits of capital.


In his analysis of this tension, the political theorist Marshall Berman names “the politics of authenticity” as “a dream of an ideal community in which individuality will not be subsumed and sacrificed, but fully developed and expressed.”


The expressive impulse of romantic modernity is that persons should be truly themselves. The administrative demand of high modernity is that they should be properly identifiable. These first-person and third-person perspectives on the lives of individuals are, in fact, deeply connected. The politics of authenticity is entwined with the politics of authentication.


To be in society is to be visible to others, to be recognized as such, and to see others visible to you.4 As technologies of visibility change, so too do the baseline conditions of social existence and participation.


For most, though, the ability to opt out of surveillance is constrained by the desire to participate, to be where social life is happening, even if their desire to be monitored is not that strong. The absence of privacy is expected, disliked, and tolerated—all the more since corporations, too, carefully design interfaces to cultivate a sense of ignorance or helplessness.6


At its absolute limit, anonymity is a sort of hermetic oblivion: you exist, but you are not in any way visible to others. In a less stringent manner, forms of “public anonymity” provide a kind of participatory freedom. These are more properly thought of as some form of pseudonymity. Named identities exist and persist over time and in public, maybe to a spectacular degree, but it is difficult to connect this public identity to any specific person or people behind it.


The possibility of anonymity comes to depend instead on the deliberate development of systems and procedures explicitly designed to ensure it. Interstitial liberty dries up as the gaps between systems are closed. Aspirations to recover something like it can be seen in the effort to create some sort of “right to be forgotten.”


Individual strategies rely on encryption, multiple identities, avoidance, sabotage by way of false or misleading information, or calculated efforts at disappearance.18 Though these methods may be successful, a world with a high baseline of visibility makes them ipso facto suspicious. Why would someone work so hard to evade scrutiny if they did not have something illicit to hide?


For individuals, privacy threatens to become not the preservation of interstitial liberty but rather the accumulation of secrets, and secrets are associated with stigma.


As David Lyon puts it, “not only being watched but watching itself has become a way of life.”22 As has, arguably, watching oneself being watched.


Social life is all about the dread that accompanies our awareness that we can never access what the other sees. We can only guess.23


Catholic sociologist Ivan Illich argued that society needed to be “deschooled.” By this he meant that the functions of education and training needed to be deinstitutionalized and the cultivation of knowledge returned to a loosely connected network of people cooperatively solving problems. He thought people should discover and learn things together in the context of immediate tasks at hand. To this end he imagined “learning webs,” something like a bulletin board or knowledge-matching system for a whole society:


For Illich, “deschooling” was about flattening and decentralizing the domain of knowledge. This was not just practical good sense—that is, a matter of more effectively bringing relevant knowledge to where it needed to be applied—but also a kind of social freedom enjoyed by people working and living their lives together, which he called “conviviality.”


Now, knowledge never settles. It is provisory and conflicted, a dynamic, gushing, never-ending flow of data and updates.33 Its distribution is fragmented and disaggregated.


The result is that the knowledge and information people have easy access to tends to be distributed according to popularity, market power, and estimated relevance to the individual—or, rather, that the mode of distribution is what now tends to count as knowledge.


The very notion of epistemic authority has changed. There has been a shift in “the sense by which we take our bearings in the world.”42 In the process, the older knowledge monopolies of the media, professions, and sciences have taken an epistemic beating.43


This is the second step on the road to selfdom. When it comes to developing their beliefs and finding evidence to support them, people cultivate a “searching disposition” to explore the web of information available to them.44 The authority of experts to dispense answers is increasingly outflanked and undermined by this disposition.


Francesca Tripodi has described how people approach search engines as truth finders designed to help them sift and sort the web’s plentiful offerings into the believable and the deceptive.45 As people do their research, they might even feel like good citizens doing their due diligence. After all, they are forming an opinion for themselves through a process of fact gathering and reflection. The difficulty is that the beliefs they bring to the search process itself, embedded in the vocabulary they use to consult the search engine, together with their whole search history, may yield results that conform to their already well-structured world.


A searching disposition is not simply the desire to look for and accept the first thing that confirms one’s prejudices; it is also the tendency to search and connect across a network of knowledge without constraint, and to justifiably expect a reasonable degree of success.


So many routine tasks involve finding things: a place to stay, and the way to get there; a book or article; a good or service; a piece of information. The expectation is that we will do it ourselves.


For better or for worse, it is through their arbitration that small and large conflicts are settled. They provide a technical framework and cultural script for how to be a member of society. Their moral valence is high. You must search.48 It is a skill one ought to cultivate, a kind of civic expectation, even a species of professional responsibility—and one that pertains specifically to individuals.


Rather, one is expected to explicitly locate oneself within a universe of highly differentiated, externalized, socially recognized categories. Aspects of experience, especially those that relate to the experience of oppression, become elements of identities that ought to be expressed, settled upon, and flagged.


More generally, the redistribution of both status (in terms of “recognition”) and resources along lines of social difference comes to be understood as a critical aspect of the quest for justice.51 A distinctive form of microlegitimacy emerges from speaking as a member of some precisely defined category, while keeping the views of those who cannot claim membership at bay.


The inexhaustible nuance of classification situations pushes right down to individuals, obscuring the central need of any kind of broad-based political movement to bracket the myriad particularities of its membership for the sake of a broader sense of belonging. The characteristic modes of failure here are, first, direct fragmentation into smaller and often ephemeral groups; second, the emergence of an internal hierarchy of classes based on some inevitably moralized criterion of authenticity or worthiness; and, third, the dogmatic assertion of some single dimension of identity as the only one that is truly real or politically relevant, with everything else relegated to some secondary status.


But this kind of populism is hard to sustain because, for the Right as much as the Left, the downward pressure in an ordinal society is fundamentally individualizing.


Populism is not native to the digital society, but the latter’s characteristically flat, hyperreactive, and teeming knowledge economy certainly stimulates reactionary impulses, born out of opportunism and distrust.


The agora overwhelms the polis. It is up to the individual to skillfully navigate the flood-tide of content.


There is a sort of elective affinity between the deployment of the ordinal society and the elevation of a radical, entrepreneurial kind of individualism in popular and sometimes scientific culture.


The original conception and extension of social rights thrived on a solidaristic foundation within a particular societal community. In effect it meant “the nation,” however narrowly defined. By contrast, “ordinal citizenship” is a form of social inclusion that depends on the universal and precise measurement of imprecise ideals of intrinsic equality, personal merit, and social value.


Rather than disappearing, economic and social differences were legitimated via the morally impeccable seal of a college diploma. Marshall had anticipated all of this when he characterized the fundamental dilemma of liberalism: “The right of the citizen in this process of selection and mobility is the right to equality of opportunity. Its aim is to eliminate hereditary privilege. In essence it is the equal right to display and develop differences, or inequalities; the equal right to be recognised as unequal.”


No one was as biting in his analysis of the new order as British sociologist and Labour Party intellectual Michael Young. In a satire published in 1958, he coined the term “meritocracy” and described its consequences as a cruel liberal fantasy.


In a substantially later revision, written toward the end of his life, Young blasted the sense of entitlement that a meritocratic system produced and predicted a populist revolt against it, born out of resentment.17


Most recently, and bearing out the core of Young’s analysis, educational attainment has begun to displace income as the primary axis of political division in Europe and the United States.20


Indeed, popular belief in self-reliance seems to have risen in step with income inequality, particularly among the working class in the Western world.


But why did neoliberal citizenship become ordinalized? We should not underestimate the power of crisp, quantitative forms of valuation when considering the medium through which meritocratic ideas circulate. (After all, the original meritocratic ideal—which may not yet have been called that—developed in tandem with formal systems of evaluation, like school grades and standardized tests.)29 Numbers seem more trustworthy. They make it easier to deal with the messiness of politics and social competition.30


Indeed experimental evidence suggests that, relative to more narrative forms of valuation, scores or grades are more likely to be taken for granted, tend to reinforce the belief that people get what they deserve in life, and in general make people think better of the overall inequalities they observe.31 Whatever the precise cause, the scoring of individual persons appears both less contentious and fairer.


The second half of the twentieth century was less about defining new substantive rights and more about extending already enumerated rights to previously excluded groups or guaranteeing their implementation for poorly served populations. This is what Judith Shklar, writing about the United States, termed “the quest for inclusion.”37


As Barbara Underwood put it more than four decades ago, “a nonracial predictor that correlates highly with race [in this case a credit score] has some of the effects of selection based explicitly on race.”42 If credit scores are racialized in this way, nonwhite people will face adverse consequences when these scoring methods are used out in the world, which is exactly what we observe.43


When a battery of legal rules and computing technologies prevents group characteristics from directly determining outcomes, why does their effect remain so stubbornly persistent? The naive answer is simply to see this gap as a well-measured but problematic group behavior. A better answer is that rationalized measurement systems (such as credit scoring) necessarily come up short.44 These methods cannot properly capture historical and present-day patterns of exclusion and exploitation that provide the raw material for people’s experiences and cultural formations.


Anything from being preyed upon by sketchy lenders to the good fortune of having a parent who will quietly pay a bill on your behalf is recorded, in effect, as a poor or wise decision by you personally.


What should the politics of ordinal citizenship be in conditions where history and social structure are rendered indistinct by the individualization of data and transformed into folktales of grit and hard work by the moralization of measurement?


Even at its best, it means that people’s movement up and down any ordinal scale of worth may have less to do with their own actions and more to do with shifts in whatever objective function the market is optimizing on given the circumstances.


As one of Veena Dubal’s interviewees, a rideshare driver, puts it, gig work feels “like gambling. The house always wins!”57 Similarly, Hatim Rahman’s ethnography of a freelance work platform describes algorithmic management as an “invisible cage,” where the criteria of control are illegible and fluctuate unpredictably.


Machine learning magnifies this problem. Rather than demanding specific kinds of inputs, data may be dredged to discover patterns with “virtually no pre-established conceptions” about its structure of meaning.


Les dés sont pipés.


As they have spread through occupations, ordinal regimes have generated discontent and legal challenges, or provoked workarounds and organized resistance.68 But their increasing ubiquity across all domains of life makes a unified challenge difficult to envision, let alone organize.69 The result is a kind of universal personalization. Each and every person’s value is determined by methods that are in one sense quite general but in another very specifically tailored.


Optimization tends to reorganize moral intuitions by way of people’s willingness to experience the positive, real-world outcomes associated with high scores as naturally deserved, as the consequence of being a good, reliable, popular, and trustworthy person.71 It is tempting to say that, in a reversion to a much older, almost religious orientation to the mysteries of Divine Providence, the more opaque the evaluation process, the more willing people may be to believe that what is being recognized and rewarded is their own personal merits, their own worthy character.


Digital systems only know and manage fragments of ourselves, but they still maintain the cultural fiction of a knowable, purposeful, and agentic individual who can be measured, classified, and “civilized.” This individual has little choice but to cultivate their digitally mediated, “dividually” managed and technologically assisted self.


As Evgeny Morozov suggests, we might end up resembling “the confused analysts of the National Security Agency: unsure of the value of the data we generate, we will opt to store them for posterity. And, unsure of how to maximize that value, we will keep adding data streams in the vain hope that the value of our data portfolio (the sum total of our life) will rise.”


The fulcrum of an ordinal society is the idea of coordination by ranking and matching, where rank is derived from the objective measurement of actual behavior and matching criteria depend on the purpose at hand. These methods are put to work within markets and organizations to sort and slot people into situations and positions. In practice, as we have repeatedly emphasized, this is a patchy process, typically adapted to circumstance, and often quite broken from a technical point of view.


By making comparison mandatory, rankings normalize competition. Moreover, they push people to compete on the dimensions that the ranking method values.


In this moral universe, the creative destruction unleashed by technological advances is imagined not just as economic change but also as moral progress. Some of this flows from the “engineering” view of the world. As Fred Turner remarks, “the ethics of engineering is an ethics of ‘does it work’? If you make something that works, you’ve done the ethical thing.”


The truth, brutally acknowledged by Mises, is that the market tends to reward those with more resources: “It is true, in the market the various consumers have not the same voting right. The rich cast more votes than the poorer citizens. But this inequality is itself the outcome of a previous voting process. To be rich, in a pure market economy, is the outcome of success in filling best the demands of the consumers. A wealthy man can preserve his wealth only by continuing to serve the consumers in the most efficient way.”


Those at the very top hedge against the future by trying to build quite literal escape hatches that lead, according to taste, to a luxurious underground bunker, outer space, or New Zealand.30


The French philosophes of the eighteenth and early nineteenth centuries—people like Turgot, Condorcet, and especially Saint-Simon—are particularly good examples. They gave us the modern use of words like individualism, industrialism, and socialism. Their successor and disciple Auguste Comte coined the word sociology (and, incidentally, also altruism) as he expounded his positivist religion of scientific humanism.


Any social scientist who works with quantitative data dreams of ideal datasets: the kind of things we would collect if money, time and ethics did not restrict us. These daydreams tend toward harmless megalomania, visions of maximally comprehensive data on the whole population of interest, in real time, with vast computing power to analyze it, and no constraints on updating or extending it. At the limit, even though we know it to be absurd, we picture something like Jorge Luis Borges’s map, a perfect, one-to-one scale representation of the world.


And so social scientists face their own challenge of bad faith. Their historical position as social critics sits uncomfortably with their involvement in an academic game whose core institutions are increasingly oriented toward the market.35


Digital capitalism makes good on that promise. The acquisition process, often initiated with a gift, is easy and immediate. Its most direct implication, the possibility of sorting and thus of ordinalization, is deeply appealing. It equips organizations with the means to impose order and control, however flawed that may be. In the process it flatters and socializes people’s disposition to compete.


Meanwhile, alternatives to rationalized calculation are enjoying a revival. Under the banner of social justice, and in the name of excluded groups, progressive elites have rejected standardized testing and called for more informal and narrative modes of assessment once decried for being subjective and arbitrary.


What is it that they mourn? It is more than personal anxiety about a future that seems to escape their power and threatens to render them irrelevant. It is the unavoidable realization that the ordinal society is, as a mechanism of governance, a tangled and unfair mess. It is the sober acknowledgment that the proliferation of small-m meritocracies has installed a “hierarchical gaze” that sees social relations through the lens of quantified and ranked comparison, however ill conceived.47 It is the sad recognition that any institution that strives for this kind of orderliness, with its ideology of clean measurement of differences and its monstrous technological affordances, has difficulty accommodating a community of equals.


Public goods and collective goals are being dissolved in the acid bath of individualization and competition, leaving us increasingly alone in a hyperconnected world whose social ordering is precisely metered and, in its factitious way, inarguably “right.” Life in the ordinal society may well be unbearable.


Alexander R. Galloway, “Golden Age of Analog,” Critical Inquiry 48, no. 2 (2022): 211–32.


Carolyn Chen, Work Pray Code: When Work Becomes Religion in Silicon Valley (Princeton University Press, 2022).

---
_reference:_ 