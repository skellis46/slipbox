---
aliases: []
tags: [harmful_content]
type: "literature"

---

# Balfour, Evans, Maloney and Merry - Postdigital Intimacies for Online Safety

_previous note:_ [[harmful content project preparation]]

> Collectively, the workshop participants thought it was important that the OSB made technology companies responsible for attending to online harms and safety, formalising risk management and legal duties. Notably, this was seen as a positive since it reverses a trend whereby those who are made vulnerable by digital harms are also those made responsible for the issue. [@balfour-2023-postdigital p.18]

> As one participant noted, “tech companies are likely to choose the minimum option”, doing enough so that they are not financially penalised by the regulations, but not enough to fully protect people against online gender-based violence. [@balfour-2023-postdigital p.18]

> However, it was also noted that safety-by- design was not shared across the sector. What was needed was take-up of such practices and technological affordances, especially by larger companies like Google and Twitter. There was a sense that the tech industry knew there was a problem, but that they needed to implement innovative safety-by-design examples by other platforms to see the benefits. [@balfour-2023-postdigital p.20]

> Content moderation is a significant future direction, as well as whether this content should be moderated by people working for tech companies or by AI systems. Overall, it was proposed that human moderation supported by “block-first approaches using open-source technologies” were preferable. It was noted that, in some instances, AI was beneficial where harmful content online was vast but services were limited in their capacity to offer human moderation – the example given by Ward, for instance, was the case of exploitative or illegal pornography. However, it was also recognised that often AI was simply not qualified to recognise the complexity of abuse and gender-based violence. Participants suggested that AI moderation only had human-based input to go on, and a culture of sexism and misogyny may end up reproducing the same challenges evident in wider culture. [@balfour-2023-postdigital p.20]

> focus on content moderation is itself insufficient, and focused on symptoms rather than causes. [@balfour-2023-postdigital p.25] (this is taking about men's and boy's health)

---
_reference:_ Balfour, L., Evans, A., Maloney, M., and Merry, S.K. (2023) _Postdigital Intimacies for Online Safety_ [online] Coventry: Coventry University. available from <[https://pure.coventry.ac.uk/ws/portalfiles/portal/66365663/Postdigital_Intimacies_for_Online_Safety.pdf](https://pure.coventry.ac.uk/ws/portalfiles/portal/66365663/Postdigital_Intimacies_for_Online_Safety.pdf)> [7 August 2023]