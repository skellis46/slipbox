# Susuki - Multisensory Integration Across Exteroceptive and Interoceptive Domains Modulates Self-Experience in the Rubber-Hand Illusion


- URL: https://readwise.io/reader/document_raw_content/61332492

> Identifying with a body is central to being a conscious self. ([View Highlight](https://read.readwise.io/read/01h697k346hg0p0r8bqm8d88vb))


> Our results demonstrate that interoceptive signals directly inﬂuence the experience of body ownership via multisensory integration,
>  and they lend support to models of conscious selfhood based on interoceptive predictive coding. ([View Highlight](https://read.readwise.io/read/01h697jqakr2wa1fk8wnv2rrvk))


> Tadi, Metzinger, & Blanke, 2007) o ([View Highlight](https://read.readwise.io/read/01h69a3g5jvq541psf7ybxxzrp))


+++++ 
- Note: look up


> The experience of body ownership (EBO) – of owning and
>  identifying with a particular body – is a central aspect of selfhood
>  (Bermudez, Marcel, & Eilan, 1995; Blanke, 2012; Blanke &
>  Metzinger, 2009). Although under normal circumstances EBO
>  appears highly stable, there is increasing evidence to indicate that
>  EBO depends on dynamic “on-the-ﬂy” multisensory integration of
>  self-related signals and is hence surprisingly open to change. ([View Highlight](https://read.readwise.io/read/01h697mhx0v8smz392ggzr5e24))


> A separate tradition emphasizes the impor-
>  tance of interoception – the sense of the internal physiological state
>  of the body – in underpinning the sense of self (Craig, 2009;
>  Critchley, Wiens, Rotshtein, Ohman, & Dolan, 2004; Damasio,
>  2010; Seth, Suzuki, & Critchley, 2011). Interoceptive representa-
>  tions reﬂect the perception of the body from the inside and
>  contribute to the regulation of physiological integrity (home-
>  ostasis) and associated affective feelings, drives and emotions.
>  A central theme within these models is that selfhood emerges
>  through elaboration of interoceptive representations and their
>  integration with exteroceptive signals within cortical regions,
>  notably the anterior portions of the insular cortex. ([View Highlight](https://read.readwise.io/read/01h697qb15arn77vfcr9bjb4tp))


> Tsakiris and colleagues capitalized on individual
>  variation in interoceptive sensitivity (IS), which refers to a person's
>  ability to detect their own interoceptive signals. They report that
>  participants with lower IS are more susceptible to the RHI
>  (Tsakiris, Tajadura-Jimenez, & Costantini, 2011) and exhibit larger ([View Highlight](https://read.readwise.io/read/01h697v4p7jqpzxqxe8z8en2na))


> changes in self-other boundaries during the enfacement illusion
>  (Tajadura-Jimenez, Longo, Coleman, & Tsakiris, 2012; Tajadura-
>  Jimenez & Tsakiris, in press). ([View Highlight](https://read.readwise.io/read/01h697v8ahc0jy3hhnwaqs8c6p))


> We interpret our results
>  in the light of emerging models of selfhood based on “predictive
>  processing” which focus existing multisensory integration
>  accounts (e.g., Makin, Holmes, & Ehrsson, 2008) by positing that
>  experiences of selfhood and body ownership are determined by
>  the brain's estimation of the most likely interpretation of the
>  ensemble of self-related signals, computed according to Bayesian
>  principles (Apps & Tsakiris, 2013; Friston, Daunizeau, Kilner, &
>  Kiebel, 2010; Seth et al., 2011). ([View Highlight](https://read.readwise.io/read/01h6985a5pnxcjs8a1v3yg2hn2))


> Here, we address this question by implementing a novel
>  “cardiac rubber hand illusion” capitalizing on augmented reality
>  (AR) technology and integrating this with physiological (cardiac)
>  monitoring. This approach allows us to superimpose a “virtual
>  rubber hand” within a participant's visual ﬁeld, the visual appear-
>  ance of which can be modulated by cardiac signals such that the
>  modulation is either in synchrony, or out of synchrony, with the
>  participant's actual heartbeat. ([View Highlight](https://read.readwise.io/read/01h6980tn2mj5ttv1m28azb6sa))


> . The peak color modulation in cardio-visual feedback was
>  then timed to coincide with peak systolic pressure (200–250 ms, we used a value of
>  210 ms following estimated R-wave). This peak pressure is when aortic barorecep-
>  tors are most active and is also when heartbeats are typically perceived in tests of
>  interoceptive sensitivity (Brener, Liu, & Ring, 1993; Wiens & Palmer, 2001). ([View Highlight](https://read.readwise.io/read/01h699e1d720eaxnrnpryrtf1f))


> PDDs were signiﬁcantly larger for synchronous
>  versus asynchronous cardio-visual feedback in the “cardiac still” but not the
>  “cardiac move” condition. P ([View Highlight](https://read.readwise.io/read/01h69a6vhwmcb2gpwmarre8h32))


+++++ 
- Note: Curious if they discuss why not sig diff in the cardiac move condition (fingers moving) -- seems to imply that we are more 'tuned' to the body when still.


> Individual IS was measured by a “feedback” task based on Whitehead, Drescher,
>  Heiman, and Blackwell (1977), in which participants were asked to judge whether
>  auditory cardiac feedback was synchronous or asynchronous with their heartbeat.
>  Auditory feedback was provided as 150 ms pulses of a 2000 Hz tone, which in the
>  synchronous condition, were timed to occur 230 ms after the electrocardiographic
>  R-wave signifying diastole (estimated to occur 120 ms prior to oximeter onset);
>  asynchronous feedback was generated by altering the estimated heart-rate to be
>  either faster (130%) or slower (70%) than that recorded by the oximeter. Partici-
>  pants completed 16 trials each lasting 10 s, 8 with synchronous and 8 with
>  asynchronous (50% faster, 50% slower) feedback. IS was calculated as the propor-
>  tion of correct trials. We chose this method as opposed to an alternative based on
>  counting heartbeats (Schandry, 1981) because it depends on comparing interocep-
>  tive and exteroceptive (auditory) signals and plausibly involves multisensory
>  integration. ([View Highlight](https://read.readwise.io/read/01h699w4nqm0c0wta6y9avvajc))


> 1) but not “cardiac
>  move” (t(20) ¼0.416, p¼0.682); see Fig. 4A. While tactile-visual
>  synchrony is obviously easy to notice for every participant (indeed it
>  is rarely tested in the classical RHI), the ﬁnding that cardio-visual
>  synchrony could also be detected (in the absence of distracting hand
>  movements) raised the possibility that the modulation of experience
>  of ownership in this condition may be mediated by awareness of this
>  relation. ([View Highlight](https://read.readwise.io/read/01h69akeq71dkp4x3ern9ne2tr))


+++++ 
- Note: movement is distracting.

## New highlights added July 30, 2023 at 5:12 PM

> These
>  differences could account for the discrepant results at least in part,
>  especially when recalling that our choice of IS method (Whitehead
>  et al., 1977) was motivated by its reliance on comparing interoceptive
>  and exteroceptive (auditory) signals: this method may be more likely
>  to bemodulatedbyprocessesunderlyingmultisensoryintegration
>  than the alternative “counting” method (Schandry, 1981). ([View Highlight](https://read.readwise.io/read/01h6e2mfsr3ny7ek8nqdn43mh4))


> We sought to determine whether multisensory integration across
>  exteroceptive and interoceptive domains inﬂuences the experience
>  of body ownership (EBO) in a version of the rubber-hand illusion. We
>  combined augmented reality (AR) and simultaneous physiological
>  monitoring to implement a “virtual rubber hand” on which we
>  projected cardio-visual feedback so that the visual appearance of the
>  virtual hand was modulated by cardiac signals, either in-time or out-
>  of-time with each participant's heartbeat. We further examined the
>  role of proprioceptive-visual integration induced by ﬁnger move-
>  ments, and we related our observations to individual differences in
>  interoceptive sensitivity (IS). The ﬁndings establish directly that
>  multisensory integration of exteroceptive and interoceptive signals
>  can modulate EBO in the rubber hand illusion. Speciﬁcally, we found
>  that synchronous (as compared to asynchronous) cardio-visual feed-
>  back ledtoanenhancedexperience of ownershipof the virtualhand
>  (condition “cardiac still”), as measured objectively by proprioceptive
>  drift (Fig. 2), andsubjectivelybyquestionnaire (Fig. 3). This observa-
>  tion extendspreviousstudiesshowingcorrelationsbetween IS and
>  susceptibility to illusions ofbody ownership (Tsakiris et al., 2011)and
>  associations between speciﬁc physiological measures and RHI induc-
>  tion (Barnsley et al., 2011; Moseley et al., 2008). ([View Highlight](https://read.readwise.io/read/01h6e231s1kg319hkvbkjbw7ph))


> A second possible explanation turns on the observation that
>  the classical RHI fake hand (as used by Tsakiris et al., 2011)is
>  usually very distinct visually from the appearance of a partici-
>  pant's real hand, whereas the virtual hand in our paradigm is a
>  high-ﬁdelity three-dimensional visual copy of each participant's
>  real hand. Thus, if high IS individuals place a higher weighting on
>  interoceptive signals (Tsakiris et al., 2011), this could lead to a
>  higher a priori willingness to accept the virtual hand in our
>  paradigm, as compared to the classical RHI where the a priori
>  plausibility of a rubber hand being part of the body is relatively
>  low. This difference in a priori plausibility could account for the
>  opposite relationships between IS and PDD in the two paradigms,
>  since synchronous tactile-visual feedback would be incongruent
>  with the prior in the classical RHI, and congruent with the prior in
>  our study. Taking this idea further it could be argued that our
>  paradigm assesses the extent to which participants feel embodied
>  in their own body (albeit with conﬂicting proprioceptive signals),
>  as compared to the classical RHI which assesses susceptibility to
>  incorporation of foreign bodies or body parts within the body
>  image. Further research is warranted discriminate these possible
>  explanations and to explore systematically how individual differ-
>  ences in IS correlate with susceptibility to manipulations of EBO
>  across paradigms. ([View Highlight](https://read.readwise.io/read/01h6e2qdfzgvngwbcyh362mvsp))


> Condition “cardiac move” elicited strong EBO as
>  measured by both methods. This condition tested effects during both
>  (synchronous or asynchronous) types of cardio-visual feedback with
>  congruent (always synchronous) visual remapping of intentional
>  ﬁnger movements onto the virtual hand. Interestingly, neither
>  objective nor subjective measures differed as a function of cardio-
>  visual feedback, indicating that in this condition the integration of
>  proprioceptive and visual signals induced by the ﬁnger movements
>  dominated the inﬂuence of interoceptive feedback on EBO. ([View Highlight](https://read.readwise.io/read/01h6e24r5xnqqy6zbnkhkjgz7h))


> The RHI has been explained with reference to models of multi-
>  sensory integration which propose that conﬂicts between vision,
>  touch, and proprioception are minimized by visual capture of visual
>  and felt (tactile) events occurring in close peri-hand space, on the
>  basis of statistical correlations among sensory signals together with
>  visual dominance (Botvinick & Cohen, 1998; Makin et al., 2008). This
>  process is argued to update self-representations to incorporate the
>  fake hand. However, updating of self-representations is evidently
>  constrained by prior “beliefs” on the reliability of sensory input (e.g.,
>  vision dominates proprioception in the classical RHI) and on the
>  plausibility of an object being part of the body. The latter point is
>  amply demonstrated by abolition of the RHI for non-hand-like
>  objects (Tsakiris, Carpenter, James, & Fotopoulou, 2010),and by
>  implausibly oriented or positioned fake hands (Ehrsson, Spence, &
>  Passingham, 2004; Lloyd, 2007; Tsakiris & Haggard, 2005). The
>  importance of peri-hand space can also be considered as a prior, in
>  the sense that sensory signals inferred to closely aligned spatial
>  locations are more likely to be interpreted as arising from a common
>  source. These observations are consistent with an emerging theore-
>  tical view of selfhood based on predictive coding which extends
>  multisensory integration accounts (Apps & Tsakiris, 2013; Seth et al.,
>  2011) and which also well accounts for both the interoceptive and
>  proprioceptive effects in the present results. ([View Highlight](https://read.readwise.io/read/01h6e2ydjjtvebgtmayjct5rcg))


> The strong experience of ownership during the “cardiac move”
>  condition for both synchronous and asynchronous cardio-visual feed-
>  back also makes sense in light of a predictive coding account. In this
>  condition, while there remains a conﬂict in global (relative to the
>  body) proprioceptive signals, the visual remapping of ﬁnger move-
>  ments to the virtual hand induces strong correlations between visual
>  signals and local (hand-related) proprioceptive input. This is another
>  example of active inference increasing the likelihood of incorporating
>  the virtual hand into the body image, as compared to the “cardiac still”
>  condition where no such movement-based active inference takes
>  place. Thus, in the “cardiac move” condition the visual and proprio-
>  ceptive signals are given sufﬁciently high weighting to suppress the
>  inﬂuence of interoceptive prediction error on the most likely pre-
>  dictive model. ([View Highlight](https://read.readwise.io/read/01h6e3hvs4d9cq4qp903asyxhx))


> On this view, self-representations consist
>  in multi-level (hierarchical) generative (i.e., predictive) models of the
>  causes of those sensory signals which are deemed most likely to be
>  “me” (Apps & Tsakiris, 2013). In Bayesian terms, this is the posterior
>  probability of the most likely generative model (self-representation)
>  given a set of priors and current sensory input. Crucially, minimiza-
>  tion of prediction errors – such as those induced by multisensory
>  conﬂicts during the RHI – will update the posterior probabilities and,
>  over time, can induce changes in priors (perceptual learning). In
>  addition, priors reﬂecting high-level representations such as “self”
>  and body-ownership are likely to operate at relatively abstract
>  multisensory levels. Thus, statistical correlations among highly
>  weighted sensory signals (vision, touch) can overcome prediction
>  errors in a different modality (proprioception) leading to a revised
>  multisensory generative (predictive) model which minimizes the
>  overall level of self-related prediction error by incorporating the fake
>  hand as part of the self-representation. ([View Highlight](https://read.readwise.io/read/01h6e2zwgzx6rh8spdhhnysa8y))


+++++ 
- Note: read Apps and Tsakiris 2013


> The “cardiac move” condition also highlights important connec-
>  tions between experiences ofagency (i.e., the experience ofbeing the
>  author of an action) and ownership (David, Newen, & Vogeley, 2008;
>  Tsakiris et al., 2010). ([View Highlight](https://read.readwise.io/read/01h6e3k73v9ydm7gq1qjvd0290))


> Our results ﬁt nicely into such a predictive framework when it is
>  extended to incorporate interoceptive signals. “Interoceptive predic-
>  tive coding” (Seth et al., 2011; Critchley & Seth, 2012) is essentially
>  the idea that interoceptive self-representations – and emotional
>  feeling states – arise from generative models of causes (both external
>  and internal) of interoceptive afferents. In relation to the RHI this
>  means that interoceptive signals constitute just one more sensory
>  modality to be incorporated into multisensory predictive models of
>  the body and self. Thus, statistical correlations between interoceptive
>  (e.g., cardiac) and exteroceptive (e.g., visual) signals can lead to
>  updating ofpredictive models of self-signals through minimization of
>  prediction error, just as may happen for exteroceptive multisensory
>  conﬂicts in the classic RHI. In other words, there is no need to assume
>  distinct modes of inﬂuence of exteroceptive and interoceptive signals
>  on EBO, for example that the former is based on multisensory
>  integration and the latter on trait-based modulation of this integra-
>  tion (Tsakiris et al., 2011). ([View Highlight](https://read.readwise.io/read/01h6e35mxy7rjrhpz3ndm83day))


> Other recent results correlating
>  individual IS with susceptibility to changes in self-representation
>  under multisensory stimulation have also been interpreted within
>  this emerging framework (Tajadura-Jimenez & Tsakiris, in press). ([View Highlight](https://read.readwise.io/read/01h6e38gnpqpqd6p7azxtwz5xe))


> A framework of predictive multisensory integration across
>  interoception and exteroception is further supported by anatomi-
>  cal and neuroimaging evidence. The right-hemisphere anterior
>  insular cortex provides one cortical focus for the integration of
>  exteroceptive and interoceptive signals (Craig, 2009; Critchley &
>  Harrison, 2013; Critchley et al., 2004; Seth et al., 2011). This region
>  has been proposed as a neural substrate for self-awareness in the
>  form of the “material me” (Craig, 2009), and is activated by
>  mismatches between predicted and actual interoceptive signals
>  induced by false physiological feedback (Gray, Harrison, Wiens, &
>  Critchley, 2007). ([View Highlight](https://read.readwise.io/read/01h6e39dgkaafzcc0ren2rkbcc))


> the right insular
>  lobe could form a central hub within a functional network
>  instantiating predictive models of body ownership and self. ([View Highlight](https://read.readwise.io/read/01h6e3gfzgamp1by11kefzczdj))

