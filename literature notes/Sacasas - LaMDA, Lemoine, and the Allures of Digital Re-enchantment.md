---
aliases: 
tags: 
type: literature
---

# Sacasas - LaMDA, Lemoine, and the Allures of Digital Re-enchantment

_previous note:_

https://theconvivialsociety.substack.com/p/lamda-lemoine-and-the-allures-of


> And while I don’t think this describes Lemoine as far as I can tell, it is worth noting how the body is, in fact, an object of scorn among those technologists with posthumanist inclinations.

> Ian Bogost explored one plausible answer in an essay for The Atlantic. “We’re all remarkably adept,” Bogost noted, “at ascribing human intention to nonhuman things.” We do it all the time. Consider the related tendency to see human faces in non-human things, a specific subset of the phenomenon known as pareidolia, which is the tendency to assign meaning to seemingly random patterns. We are meaning-seeking and meaning-making animals. But we seem to be especially prone to seek after our own likeness.2 Perhaps facial pareidolia might be better understood as social pareidolia, which is to say that what our minds are too keen to discover in the world are others like us. In short, there are two simple but powerful human desires at work: We want things to make sense on our terms and we do not want to be alone.

> Cross give us one especially fraught example:
> It gets creepier. Systems engineer and historian Lilly Ryan warns that what she calls ecto-metadata—the metadata you leave behind online that illustrates how you think—is vulnerable to exploitation in the near future. Imagine a world where a company created a bot based on you and owned your digital “ghost” after you’d died. There’d be a ready market for such ghosts of celebrities, old friends, and colleagues. And because they would appear to us as a trusted loved one (or someone we’d already developed a parasocial relationship with) they’d serve to elicit yet more data. It gives a whole new meaning to the idea of ‘necropolitics.’ The afterlife can be real, and Google can own it.

> Necropolitics, yes, and necrocapitalism, too.

> But such companionship comes at a cost. In his response to Lemoine’s claims about LaMDA, Noah Millman argued that “we ourselves have increasingly been trained by A.I.s to modify our behavior and modes of communication to suit the incentive structure built into their architecture.” “We are surrounded by algorithms that are purportedly tailored to our preexisting preferences,” Millman added, “but the process of being so surrounded is also training us to be algorithmically tractable.”

---
_reference:_ 