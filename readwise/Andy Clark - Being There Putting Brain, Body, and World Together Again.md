# Being There Putting Brain, Body, and World Together Again

![rw-book-cover](https://readwise-assets.s3.amazonaws.com/static/images/default-book-icon-7.09749d3efd49.png)

## Metadata
- Author: [[Andy Clark]]
- Full Title: Being There Putting Brain, Body, and World Together Again
- Category: #books

## Highlights

> But, for all that, a version of the old opposition between matter and mind persists. It persists in the way we study brain and mind, excluding as "peripheral" the roles of the rest of the body and the local environment. It persists in the tradition of modeling intelligence as the production of symbolically coded solutions to symbolically expressed puzzles. It persists in the lack of attention to the ways the body and local environment are literally built into the processing loops that result in intelligent action. And it persists in the choice of problem domains: for example, we model chess playing by programs such as Deep Thought5 when we still can't get a real robot to successfully navigate a crowded room and we still can't fully model the adaptive success of a cockroach. (Location 35)


> In the natural context of body and world, the ways brains solve problems is fundamentally transformed. (Location 40)


> This makes the crucial point that treating cognition as pure problem solving invites us to abstract away from the very body and the very world in which our brains evolved to guide us. (Location 47)


> Might it not be more fruitful to think of brains as controllers for embodied activity? That small shift in perspective has large implications for how we construct a science of the mind. It demands, in fact, a sweeping reform in our whole way of thinking about intelligent behavior. (Location 48)


> Being There didn't come from nowhere. The image of mind as inextricably interwoven with body, world, and action, already visible in Martin Heidegger's Being and Time (1927), found clear expression in Maurice Merleau-Ponty's Structure of Behavior (1942). (Location 57)


> We ignored the fact that the biological mind is, first and foremost, an organ for controlling the biological body. Minds make motions, and they must make them fast—before the predator catches you, or before your prey gets away from you. Minds are not disembodied logical reasoning devices. (Location 94)


> This shortcoming has nothing to do with the relative paucity of the knowledge the system explicitly encodes. Rather, it is attributable to the lack of any fluent coupling between the system and a real-world environment posing real-world problems of acting and sensing. (Location 130)


> Intelligence and understanding are rooted not in the presence and manipulation of explicit, language-like data structures, but in something more earthy: the tuning of basic responses to a real world that enables an embodied organism to sense, act, and survive. (Location 135)


> Our prejudice against basic forms of biological intelligence and in favor of bigger and fancier "filing cabinet/logic machines" goes all too deep. (Location 157)


> Once mind is cast as a controller of bodily action, layers upon layers of once-received wisdom fall away. The distinction between perception and cognition, the idea of executive control centers in the brain, and a widespread vision of rationality itself are all called into question. (Location 203)


> A vertical microworld is one that slices off a small piece of human-level cognitive competence as an object of study. Examples include playing chess, producing the past-tense forms of English verbs, and planning a picnic, all of which have been the objects of past AI programs. (Location 233)


> Neat, design-oriented solutions to these recent problems may thus be quite unlike the natural solutions dictated by the need to exploit existing machinery and solutions. We may be chess masters courtesy of pattern-recognition skills selected to recognize mates, food, and predators. (Location 237)


> A horizontal microworld, in contrast, is the complete behavioral competence of a whole but relatively simple creature (real or imaginary). By studying such creatures, we simplify the problems of human-level intelligence without losing sight of such biological basics as real-time response, integration of various motor and sensory functions, and the need to cope with damage. (Location 238)


> Brooks (1991, p. 143) lays out four requirements for his artificial creatures: A creature must cope appropriately and in a timely fashion with changes in its dynamic environment. A creature should be robust with respect to its environment. . . . A creature should be able to maintain multiple goals A creature should do something in the world; it should have some purpose in being. (Location 241)


> The ingenious strategies and tricks that enable embodied systems to maintain coherence while exploiting multiple, special-purpose, quasi-independent problem-solving routines (addressed in later chapters) shed light on the roles of language, culture, and institutions in empowering human cognition. (Location 330)


> Thus, an emulator provides for a kind of motor hyperacuity, enabling us to generate smoother and more accurate reaching trajectories than one would think possible in view of the distances and the speed of conduction governing the return of sensory signals from bodily peripheries. (Location 365)


> The idea of niche-dependent sensing is not new. In 1934 Jakob Von Uexkull published a wonderful monograph whose title translates as A Stroll through the Worlds of Animals and Men: A Picture Book of Invisible Worlds. Here, with almost fairy-tale-like eloquence and clarity, Von Uexkull introduces the idea of the Umwelt, defined as the set of environmental features to which a given type of animal is sensitized. He describes the Umwelt of a tick, which is sensitive to the butyric acid found on mammalian skin. Butyric acid, when detected, induces the tick to loose its hold on a branch and to fall on the animal (Location 383)


> It is impossible to resist quoting Von Uexkull at some length: (Location 389)


> Out of the vast world which surrounds the tick, three shine forth from the dark like beacons, and serve as guides to lead her unerringly to her goal. To accomplish this, the tick, besides her body with its receptors and effectors, has been given three receptor signs, which she can use as sign stimuli. And these perceptual cues prescribe the course of her actions so rigidly that she is only able to produce corresponding specific effector cues. (Location 392)


+++++ 
- Note: Umwelt. Quoting Uxwell. Curious re beside body. Body as object.


> Frequent saccades enable us, animate-vision researchers claim, to circumvent the need to build enduring and detailed models of our visual surroundings. Instead, to borrow a slogan from Rodney Brooks, we can use the world as its own best model and visit and revisit the real-world scene, sampling it in detail at specific locations as required. (Location 434)


> For all that, it certainly seems to us as if we are usually in command of a full and detailed three-dimensional image of the world around us. But this, as several recent authors have pointed out,10 may be a subjective illusion supported by our ability to rapidly visit any part of the scene and then retrieve detailed (but not enduring) information from the foveated region. Ballard (1991, p. 59) comments that "the visual system provides the illusion of three-dimensional stability by virtue of being able to execute fast behaviors." (Location 437)


> We do not treat the spaces between the sensory inputs as indicating spaces in the world, because we are used to using the senses as exploratory tools, moving first to one point and then to the next. (Location 445)


> Rodney Brooks's Mobile Robot Laboratory once had the motto "Fast, cheap, and out of control." Such, indeed, is the immediate message of the New Robotics vision. (Location 465)


+++++ 
- Note: Newsletter?


> Umwelt, (Location 469)


+++++ 
- Note: Newsletter? Also re bindings?


> The Rational Deliberator turns out to be a wellcamouflaged Adaptive Responder. Brain, body, world, and artifact are discovered locked together in the most complex of conspiracies. And mind and action are revealed in an intimate embrace. (Location 492)


> In fact (and to be historically fair), developmental psychologists were probably among the very first to notice the true intimacy of internal and external factors in determining cognitive success and change. In this respect, theorists such as Jean Piaget, James Gibson, Lev Vygotsky, and Jerome Bruner, although differing widely in their approaches, actively anticipated many of the more radical-sounding ideas now being pursued in situated robotics. (Location 498)


> A better image of child cognition (indeed, of all cognition) depicts perception, action, and thought as bound together in a variety of complex and interpenetrating ways. (Location 510)


> Infants do not use their crawling experience to acquire knowledge about slopes in general. Rather, they acquire knowledge about how slopes figure in specific contexts involving action. (Location 535)


> The challenge, thus, is to develop "a theoretical framework that is, as it were, 'motocentric' rather than "visuocentric" (P. S. Churchland et al. 1994, p. 60). (Location 556)


> Individual variability should thus not be dismissed as "bad data" or "noise" that somehow obscures essential developmental patterns. (Location 632)


> The idea of scaffolding has its roots in the work of the Soviet psychologist Lev Vygotsky.16 (Location 659)


> Biologists have tended to focus solely on the individual organism as the locus of adaptive structure. They have treated the organism as if it could be understood independent of its physical world. (Location 672)


> In general, evolved creatures will neither store nor process information in costly ways when they can use the structure of the environment and their operations upon it as a convenient stand-in for the information-processing operations concerned. (Location 677)


> This is not, then, to deny the existence and the importance of mediating inner states altogether. Rather, it is to insist that the inner states be "action-centered"—a theme Gibson pursues by depicting organisms as keyed to detecting "affordances" in the distal environment. Such affordances are nothing other than the possibilities for use, intervention, and action offered by the local environment to a specific type of embodied agent. (Location 722)


> Mind is a leaky organ, forever escaping its "natural" confines and mingling shamelessly with body and with world. (Location 745)


> The suspicion, however, is that cognitive science can no longer afford simplifications that take the real world and the acting organism out of the loop—such simplifications may obscure the solutions to ecologically realistic problems that characterize active embodied agents such as human beings. (Location 845)


> One central theme which has already emerged is that abstracting away from the real-world poles of sensing and acting deprives our artificial systems of the opportunity to simplify or otherwise transform their information-processing tasks by the direct exploitation of real-world structure. Yet such exploitation may be especially essential if we hope to tackle sophisticated problem solving using the kinds of biologically plausible pattern-completing resources that artificial neural networks provide, as we shall now see. (Location 849)


> Not all animals are capable of originating such systems, and not all animals are capable of benefiting from them even once they are in place. The stress on external scaffolding thus cannot circumvent the clear fact that human brains are special. But the computational difference may be smaller and less radical than we sometimes believe. It may be that a small series of neuro-cognitive differences make possible the origination and exploitation of simple linguistic and cultural tools. From that point on, a kind of snowball effect (a positive feedback loop) may take over. Simple external props enable us to think better and hence to create more complex props and practices, which in turn "turbocharge" our thought a little more, which leads to the development of even better props It is as if our bootstraps themselves grew in length as a result of our pulling on them! (Location 893)


> The moral is clear: We manage our physical and spatial surroundings in ways that fundamentally alter the information-processing tasks our brains confront. (Location 909)


> This crucial difference is nicely captured by David Kirsh and Paul Maglio (1994) as the distinction between pragmatic and epistemic action. Pragmatic action is action undertaken because of a need to alter the world to achieve some physical goal (e.g., one must peel potatoes before boiling them). Epistemic action, in contrast, is action whose primary purpose is to alter the nature of our own mental tasks. In such cases, we still act on the world, but the changes we impose are driven by our own computational and information-processing needs. (Location 928)


> Once again, it looks for all the world (pun intended) as if the classical image bundles into the machine a set of operational capacities which in real life emerge only from the interactions between machine (brain) and world. (Location 941)


+++++ 
- Note: His use of scrabble as example is useful


> No one thought, of course, that perception, motion, and action did not matter at all. All agreed that sooner or later such issues would have to be factored in. But it was widely believed that the additional problems such topics posed could be safely separated from the primary task of understanding mind and cognition, and that the solutions to these more "practical" problems could just be "glued onto" the computational engines of disembodied reason. (Location 985)


> oiepistemic credit. (Location 1005)


> A self-organizing system is one in which some kind of higher-level pattern emerges from the interactions of multiple simple components without the benefit of a leader, controller, or orchestrator. (Location 1036)


> The higherorder structure (which Resnick calls the collective structure) was thus displaying behavior fundamentally different from the behavior of its components. Indeed, the individual components kept changing (as old cars left and new ones joined), but the integrity of the higher-order collective was preserved. (In a similar fashion, a human body does not comprise the same mass of matter over time—cells die and are replaced by new ones built out of energy from food. We, too, are higher-order collectives whose constituting matter is in constant flux.) (Location 1060)


> stigmergic algorithms. (Location 1073)


> These first few chapters have, I hope, conveyed a growing sense of the opportunistic character of much of biological cognition. For example: faced with the heavy time constraints on real-world action, and armed only with a somewhat restrictive, pattern-completing style of on-board computation, the biological brain takes all the help it can get. (Location 1151)


> Cognitive science, as sketched in the preceding chapters, can be seen in terms of a three-stage progression. The first stage (the heyday of classical cognitivism) depicted the mind in terms of a central logic engine, symbolic databases, and some peripheral "sensory" modules. Key characteristics of this vision included these ideas: memory as retrieval from a stored symbolic database, problem solving as logical inference, cognition as centralized, the environment as (just) a problem domain, and the body as input device. The connectionist (artificial neural network) revolution took aim at the first three of these characteristics, replacing them with the following: memory as pattern re-creation, problem solving as pattern completion and pattern transformation, and cognition as increasingly decentralized. (Location 1200)


> To thus take body and world seriously is to invite an emergentist perspective on many key phenomena—to see adaptive success as inhering as much in the complex interactions among body, world, and brain as in the inner processes bounded by skin and skull. (Location 1210)


> Our own body is in the world as the heart is in the organism .. . it forms with it a system. —Maurice Merleau-Ponty, Phenomenology of Perception; passage translated by David Hilditch in his Ph.D. thesis, At the Heart of the World (Washington University, 1995) (Location 1220)


> where a human designer will usually build any required functionality directly into a distinct device for solving a given problem, evolution is in no way constrained by the boundaries between an organism or device and the environment. Problem solving easily becomes distributed between organism and world, or between groups of organisms. Evolution, having in a very real sense no perspective on a problem at all, is not prevented from finding cheap, distributed solutions by the kinds of blinkers (e.g., the firm division between device and operating domain) that help human engineers focus their attention and decompose complex problems into parts. (Location 1236)


> Lieberman (1984, p. 22) is thus led to comment that "swim bladders are logically designed devices for swimming—they constitute a Rube Goldberg system for breathing." (Location 1250)


> As the cell geneticist Francois Jacob (1977, p. 1163) put it: "Simple objects are more dependent on (physical) constraints than on history. As complexity increases, history plays the greater part." (Location 1253)


> Of course, the bad news about messier, more biologically realistic and interactive solutions is that they are not just hard to discover but also hard to understand once we have them. (Location 1311)


> guid finding evolved solutions which significantly (Location 1314)


> The crucial point is just that natural evolution does not operate so as to "solve" a fixed problem. Instead, the problems themselves alter and evolve in a complex web of coevolutionary change. (Location 1322)


> Finally, there is a widely acknowledged problem of "scaling up." Most of the work reported above uses genetic search applied to relatively small neural network controllers. As the number of parameters characterizing the controllers increases, standard varieties of evolutionary search become increasingly inefficient. The key to overcoming this problem seems to lie in some combination of better genetic encodings and the "offloading" of some of the burden onto the environment (i.e., reducing the amount of information encoded in the genotype by relying on developmental interactions with a structuring environment). In this way, the scaling problem and the previous phenotype/genotype problem may be more closely linked than is initially apparent.9 (Location 1332)


> On the other hand, one of the major insights driving much autonomousagent research is precisely a recognition of the unsuspected complexity of real agent-environment interactions and of the surprising ways in which real-world features and properties can be exploited by embodied beings. (Location 1343)


> By using less accurate components, it is possible to design robots in which properties of the physical device (e.g., mechanical and electrical losses) act so as to damp down responses and hence avoid undesirable variations and fluctuations. (Location 1365)

