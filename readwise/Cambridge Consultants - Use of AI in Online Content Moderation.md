# Use of AI in Online Content Moderation

![rw-book-cover](https://readwise-assets.s3.amazonaws.com/static/images/article1.be68295a7e40.png)

## Metadata
- Author: [[Cambridge Consultants]]
- Full Title: Use of AI in Online Content Moderation
- Category: #articles
- Document Tags: [[harmful_content]] 
- URL: https://readwise.io/reader/document_raw_content/21600350

## Highlights

> As the amount of UGC that platform users upload continues to
>  accelerate,1 it has become impossible to identify and remove
>  harmful content using traditional human-led moderation
>  approaches at the speed and scale necessary. ([View Highlight](https://read.readwise.io/read/01h7ff7ek97rvr3mrnrres43p4))


+++++ 
- Note: p.4


> There is a broad range of content which is potentially harmful,
>  including but not limited to: child abuse material, violent and
>  extreme content, hate speech, graphic content, sexual content,
>  cruel and insensitive material and spam content. Some harmful
>  content can be identified by analysing the content alone, but
>  other content requires an understanding of the context around
>  it to determine whether or not it is harmful. Interpreting
>  this context consistently is challenging for both human and
>  automated systems because it requires a broader understanding
>  of societal, cultural, historical and political
>  factors. Some
>  of these contextual considerations vary around the world
>  due to differences in national laws and what societies deem
>  acceptable. Content moderation processes must therefore be
>  contextually aware and culturally-specific to be effective. ([View Highlight](https://read.readwise.io/read/01h7ff82cph35bg2d18ddskw9t))


+++++ 
- Note: p.4

