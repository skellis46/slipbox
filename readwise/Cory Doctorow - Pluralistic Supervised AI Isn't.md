# Pluralistic: Supervised AI Isn't

![rw-book-cover](https://i0.wp.com/pluralistic.net/wp-content/uploads/2020/02/cropped-guillotine-French-Revolution.jpg?fit=32%2C32&ssl=1)

## Metadata
- Author: [[Cory Doctorow]]
- Full Title: Pluralistic: Supervised AI Isn't
- Category: #articles
- URL: https://pluralistic.net/2023/08/23/automation-blindness/

## Highlights

> This deliberate misdirection actually reveals a deep truth about AI: that the story of AI being managed by a "human in the loop" is a fantasy, because humans are neurologically incapable of maintaining vigilance in watching for rare occurrences. ([View Highlight](https://read.readwise.io/read/01h8havvaw4pentc2st05dbswe))


> This is an inescapable, biological aspect of human cognition: we *can't* maintain vigilance for rare outcomes. This has long been understood in automation circles, where it is called "automation blindness" or "automation inattention": ([View Highlight](https://read.readwise.io/read/01h8haxtmckdsz57rbff8ag8fz))


> Here's the thing: if nearly all of the time the machine does the right thing, the human "supervisor" who oversees it becomes *incapable* of spotting its error. The job of "review every machine decision and press the green button if it's correct" *inevitably* becomes "just press the green button," assuming that the machine is usually right. ([View Highlight](https://read.readwise.io/read/01h8haye30hb77vg4akv6qpc8t))

