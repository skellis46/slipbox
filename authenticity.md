
---
aliases: 
tags: 
type: newsletter
platform: skellis mailing list
status: in progress
status-updated: "20250802"

---

# authenticity 

Dear

I was recently called an "authentic mover" and the term made me smile. It was meant in the sense of someone who practices a kind of dancing called [authentic movement](https://en.wikipedia.org/wiki/Authentic_Movement) —a term whose implications (what counts as ‘authentic,’ and who decides?) are a little strange, even troubling. But the phrase stuck with me, particularly as I’ve been spending more time immersed in the world of AI.

Over the past few months, I’ve been reading about—and using—generative AI (in this case, the large language model ChatGPT) both in my work and to help me study Italian. The rapid evolution of this technology is dizzying. Tools like the AI-driven web browser [Dia](https://www.diabrowser.com/), where you can “chat with your tabs,” are striking in their design and function. Others, like OpenAI’s [ChatGPT Agents](https://openai.com/index/introducing-chatgpt-agent/), which can autonomously carry out research and actions on your behalf, raise more troubling questions—especially around privacy and autonomy.

I’m ambivalent about using LLMs for many reasons. Not least the enormous quantity of electricity required to both train the models and generate the incalculable volume of AI inferences (or responses) to individual prompts. The tech world has unleashed an extraordinary tool at a moment when neither humanity nor the planet can afford it.

I’m also ambivalent about what these tools mean for those of us who are so-called knowledge workers. The generative power of LLMs is remarkable and seductive. More than once while writing reports and funding applications, I’ve wondered what—if anything—we do with our brains that these AIs couldn’t soon do better.

Yet even as I ask this, I’ve found myself exploring how to collaborate with AI, rather than ignore it. If I don’t, I risk holding back the work we’re trying to do as a team at the Centre for Dance Research in Coventry.

It's tricky. 

In 2024, the British developer Simon Willison popularised (in tech circles) the term [AI slop](https://en.wikipedia.org/wiki/AI_slop). It refers to the overwhelming quantity of low-quality, machine-produced content already flooding the internet. AI models are now being trained on content produced by other generative AIs—a wicked ouroboros of self-replicating sludge, driven by a kind of blind faith in the [religion of technology](https://theconvivialsociety.substack.com/p/apocalyptic-ai).

Twelve years earlier, in [Facebook's IPO Filing](https://www.sec.gov/Archives/edgar/data/1326801/000119312512034517/d287954ds1.htm), CEO Mark Zuckerberg sang Facebook’s hymn to “move fast and break things.” Innovation, for him, was predicated on speed and destruction.

But what does this speed—and this slop—actually feel like, if we pause long enough to notice?

In a [recent episode of Marina Hyde and Richard Osman's podcast _The Rest is Entertainment_](https://www.youtube.com/watch?v=Qks3M6cbpDA), they discuss AI slop and suggest that authenticity may soon become a highly prized commodity. As machine-generated images, videos, and words continue to multiply, we humans may begin to crave experiences in which the _deus ex machina_ exits stage right, and we are simply left to **move slowly and make things** with our hands.

Back in 1901, the German psychologist Karl Groos coined the phrase “the pleasure at being the cause” to describe how infants take joy in realising they can make things happen in the world. As much as the concept of authenticity has a darker side—its links to hyper-individualism and to fantasies of the ‘authentic self’—I remain hopeful.

Hopeful that the beauty and power of making tangible things will survive—or even flourish—where the machines cannot reach.





## edit bin

With so many changes in speed, scale and indeed value, it is nearly impossible to keep in mind that LLMs generate materials (text, video, images) through statistical probabilities at the level of tokens. A token is a unit of text -- either a part of a word, a whole word, or grammatical symbols -- that the LLM uses to predict (using probabilities built into the algorithmic model) what token will likely be next. The model then does this for every token at every stage of the response to a prompt. It is incomprehensible to imagine this once you see the kinds of responses you are able to get to your writing (and thinking)

From Bullshit Jobs:


> As early as 1901, the German psychologist Karl Groos discovered that infants express extraordinary happiness when they first figure out they can cause predictable effects in the world, pretty much regardless of what that effect is or whether it could be construed as having any benefit to them. Let’s say they discover that they can move a pencil by randomly moving their arms. Then they realize they can achieve the same effect by moving in the same pattern again. Expressions of utter joy ensue. Groos coined the phrase “the pleasure at being the cause,” suggesting that it is the basis for play, which he saw as the exercise of powers simply for the sake of exercising them.

> Children come to understand that they exist, that they are discrete entities separate from the world around them, largely by coming to understand that “they” are the thing which just caused something to happen—the proof of which is the fact that they can make it happen again.7 Crucially, too, this realization is, from the very beginning, marked with a species of delight that remains the fundamental background of all subsequent human experience.8 It is hard perhaps to think of our sense of self as grounded in action because when we are truly engrossed in doing something—especially something we know how to do very well, from running a race to solving a complicated logical problem—we tend to forget that we exist. But even as we dissolve into what we do, the foundational “pleasure at being the cause” remains, as it were, the unstated ground of our being.

