---
aliases: []
tags: []
type: "evergreen"
---

# AI and human causal reasoning

_previous note:_ [[Bayes and abductive reasoning]]

> [A recent Nature review](https://thenextrecession.wordpress.com/2024/06/06/ai-again/) found that, while LLMs lightened routine scientific chores, the decisive leaps of insight still belonged to humans. Human cognition is better conceptualized as a form of theory-based causal reasoning rather than AI’s emphasis on information processing and data-based prediction. AI uses a probability-based approach to knowledge and is largely backward-looking and imitative, whereas human cognition is forward-looking and capable of generating genuine novelty.

> "Unfortunately, as *MIT Tech* explains, many AI models are notorious [black boxes](https://theconversation.com/what-is-a-black-box-a-computer-scientist-explains-what-it-means-when-the-inner-workings-of-ais-are-hidden-203888), which means that while an algorithm might produce a useful output, it’s unclear to researchers how it actually got there. This has [been the case for years](https://www.technologyreview.com/2017/04/11/5113/the-dark-secret-at-the-heart-of-ai/), with AI systems often defying statistics-based theoretical models.  In other words, AI trainers don’t really know how AI models work.  That is a major obstacle to achieving the Holy Grail.

Michael Roberts <https://thenextrecession.wordpress.com/2025/07/27/ai-bubbling-up/>


---

_original source/found:_ 

_reference:_ 



